- 멀티 쓰레드 프로그래밍을 개발할 때 주의해야 할 점
    - 공유 데이터를 사용하는 코드 영역인 임계구역에서 서로 다른 쓰레드가 간섭하지 않도록 쓰레드를 동기화 시켜 신뢰성 있는 데이터와 로직이
      산출(?)될 수 있게끔 코드를 작성해야합니다. 락을 거는 행위는 성능에 영향을 미치고 데드락을 유발할 수도 있으니 조심해야 합니다.

- 쓰레드를 구현하기 위한 인터페이스, 클래스
    Runnable 인터페이스를 사용하여 람다 혹은 내부클래스로 run() 메서드 구현
    새로운 클래스를 정의하고 Thread 클래스를 상속받은 후 run() 메서드 구현

    다른 클래스를 상속받지 않아도 될 때 => Thread 클래스 상속 후 구현
    Thread 클래스에 존재하는 다른 메소드들도 사용하고 싶을 때 => Thread 클래스 상속 후 구현
    그외는 Runnable 구현

- 자바의 모든 클래스는 Object 클래스를 상속받습니다. 그리고 Object 클래스에는 equals() 와 hashCode() 라는 메소드가 선언되어 있습니다.
  이 메소드들은 각각 어떤 역할일까요? 이 둘의 차이점은 무엇일까요?   https://hyeran-story.tistory.com/123
    - equals()란?
        - equals 메소드는 기본적으로 2개의 객체가 동일한지 검사하기 위해 사용
        - 2개의 객체가 참조하는 것이 동일한지를 확인하는 것이며, 이는 동일성(Identity)을 비교하는 것
        - 동일한 메모리 주소일 경우에만 동일한 객체가 된다.

        - 하지만 프로그래밍을 하다보면 동일한 객체가 메모리 상에 여러 개 띄워져있는 경우가 있다. 해당 객체는 서로 다른 메모리에
          띄워져있으므로 동일한(Identity) 객체가 아니다. 하지만 프로그래밍 상으로는 같은 값을 지니므로 같은 객체로 인식되어야 하는데,
          이러한 동등성(Equality)를 위해 우리는 값으로 객체를 비교하도록 equals 메소드를 오버라이딩해주는 것이다.

    - hashCode()란?
        - 실행 중에(Runtime) 객체의 유일한 integer 값을 반환
        - Object 클래스에서는 heap 에 저장된 객체의 메모리 주소를 반환하도록 되어있다. (항상 그런 것은 아니다.)
        - hashCode 는 HashTable 과 같은 자료구조를 사용할 때 데이터가 저장되는 위치를 결정하기 위해 사용된다.

    - equals 와 hashCode 의 관계
        - 동일한 객체는 동일한 메모리 주소를 갖는다는 것을 의미하므로, 동일한 객체는 동일한 해시코드를 가져야 한다. 그렇기 때문에
          우리가 equals() 메소드를 오버라이드 한다면, hashCode() 메소드도 함께 오버라이드 되어야 한다.
        - Java 프로그램을 실행하는 동안 equals 에 사용된 정보가 수정되지 않았다면, hashCode 는 항상 동일한 정수값을 반환해야 한다.
          (Java 의 프로그램을 실행할 때 마다 달라지는 것은 상관이 없다.)
          두 객체가 equals()에 의해 동일하다면, 두 객체의 hashCode() 값도 일치해야 한다.
          두 객체가 equals()에 의해 동일하지 않다면, 두 객체의 hashCode() 값은 일치하지 않아도 된다.

    - hashCode() Override 의 필요성
        - hashCode 를 equals 와 함께 재정의하지 않으면 코드가 예상과 다르게 작동하는 위와 같은 문제를 일으킨다.
          정확히 말하면 hash 값을 사용하는 Collection(HashSet, HashMap, HashTable)을 사용할 때 문제가 발생
        - hashCode 메서드의 리턴 값이 우선 일치하고 equals 메서드의 리턴 값이 true 여야 논리적으로 같은 객체라고 판단한다.
          hashCode 메서드가 재정의 되어있지 않으면 Object 클래스의 hashCode 메서드가 사용됨
        - intellij 의 Generate 기능을 사용했더니 Objects.hash 메서드를 호출하는 로직으로 hashCode 메서드가 재정의 됐다.
          Objects.hash 메서드는 hashCode 메서드를 재정의하기 위해 간편히 사용할 수 있는 메서드이지만 속도가 느리다.
          인자를 담기 위한 배열이 만들어지고 인자 중 기본 타입이 있다면 박싱과 언박싱도 거쳐야 하기 때문이다.
          성능에 아주 민감하지 않은 대부분의 프로그램은 간편하게 Objects.hash 메서드를 사용해서 hashCode 메서드를 재정의해도 문제 없다.
          민감한 경우에는 직접 재정의해주는 게 좋다.

        - equals(Object)가 두 객체를 다르다고 판단했더라도, 두 객체의 hashCode 가 서로 다른 값을 반환할 필요는 없다.
          단, 다른 객체에 대해서는 다른 값을 반환해야 해시테이블의 성능이 좋아진다.
        - HashMap 의 구현은 해시 코드가 다른 엔트리끼리는 동치성 비교 자체를 하지 않도록 최적화 되어 있다.
        - hashCode 를 만드는 해시 함수를 equals 메소드를 재정의할 때 사용한 필드와 같은 필드를 사용하자.
        - 만약 객체는 같은 해시 코드를 가지게 되면 전부 같은 버킷에 해시되므로 해시 테이블은 아주 긴 링크드 리스트가 많이 생기게 될 것
        - 해시 테이블(hash table)의 평균 시간 복잡도는 O(1)이고, 최악의 로직을 가진 해시 테이블의 시간 복잡도는 O(n) 이다.
        - 만약 이 해시 테이블이 해시 충돌(hash collision) 해결을 해시 체이닝(hash chaining) 방식으로 구현했다면,
          실제 링크드 리스트(linked list) 처럼 동작한다.

    - 만약 ORM 을 사용하고 있는 경우라면, hashCode 와 equals 를 오버라이드 하는 메소드 내부에서 Getter 를 사용하기를 권장한다.
      그 이유는 ORM 에 의해 fields 가 Lazy Loaded 되어, getter 를 부르기 전에는 사용이 불가능할 수 있기 때문이다.

    - HashMap 내부 구현
        - 해싱함수를 통해 인덱스를 산출
        - 인덱스를 통한 접근으로 시간복잡도 O(1)의 빠른 성능
        - key 는 무한하지만 인덱스는 한정되어 있어 충돌은 불가피
        - 충돌을 줄이기 위해 HashMap 은 버킷의 사이즈를 조절
        - 충돌이 일어날 시, 충돌 수가 적으면 LinkedList 방식으로 충돌된 객체들을 관리하다가 임계점을 넘으면 Red-Black Tree 방식으로
          객체들을 저장
        - https://lordofkangs.tistory.com/78

    - String 객체 생성
        - new 연산자로 String 객체를 생성하면 JVM 에서 Heap 영역에서 String 객체 생성
        - new 연산자가 아닌 리터럴("")로 String 객체를 생성하면 JVM 은 우선 String Constant Pool 영역을 방문.
          거기서 같은 값을 가진 String 객체를 찾으면 그 객체의 주소 값을 반환하여 참조하게 된다. 찾지 못하면 String Constant Pool 에
          해당 값을 가진 String 객체를 생성하고 그 주소 값을 반환.
        - String Constant Pool 영역은 Heap 영역 내부에서 String 객체를 위해 별도로 관리하는 저장소.

    - https://velog.io/@tamxt4047/equals-hashCode
    - https://camel-context.tistory.com/52

- StringBuilder 와 StringBuffer 의 차이는 무엇일까요?
    - 연산이 많지 않을때는 위에 나열된 어떤 클래스를 사용하더라도 이슈가 발생할 가능성은 거의 없습니다. 그러나 연산횟수가 많아지거나
      멀티쓰레드, Race condition 등의 상황이 자주 발생 한다면 각 클래스의 특징을 이해하고 상황에 맞는 적절한 클래스를 사용해 주셔야 합니다

    - String  vs  StringBuffer/StringBuilder
        - String 클래스는 불변하기 때문에 문자열을 수정하는 시점에 새로운 String 인스턴스가 생성된
        - 새로운 메모리영역을 가리키게 변경되고 처음 선언했던 "hello"로 값이 할당되어 있던 메모리 영역은 Garbage 로 남아있다가
          GC(garbage collection)에 의해 사라지게 되는 것
        - String 은 불변성을 가지기 때문에 변하지 않는 문자열을 자주 읽어들이는 경우 String 을 사용해 주시면 좋은 성능을 기대
        - 문자열 추가,수정,삭제 등의 연산이 빈번하게 발생하는 알고리즘에 String 클래스를 사용하면 힙 메모리(Heap)에
          많은 임시 가비지(Garbage)가 생성되어 힙메모리가 부족으로 어플리케이션 성능에 치명적인 영향을 끼치게 됩니다.
        - String 과는 반대로 StringBuffer/StringBuilder 는 가변성 가지기 때문에
          .append() .delete() 등의 API 를 이용하여 동일 객체내에서 문자열을 변경하는 것이 가능

    - StringBuffer  vs  StringBuilder
        - 가장 큰 차이점은 동기화의 유무
        - StringBuffer 는 동기화 키워드를 지원하여 멀티쓰레드 환경에서 안전하다는 점
            - 참고로 String 도 불변성을 가지기때문에 마찬가지로  멀티쓰레드 환경에서의 안정성(thread-safe)을 가지고 있습니다.
        - StringBuilder 는 동기화를 지원하지 않기때문에 멀티쓰레드 환경에서 사용하는 것은 적합하지 않지만 동기화를 고려하지 않는 만큼
          단일쓰레드에서의 성능은 StringBuffer 보다 뛰어납니다.

    String          :  문자열 연산이 적고 멀티쓰레드 환경일 경우
    StringBuffer    :  문자열 연산이 많고 멀티쓰레드 환경일 경우
    StringBuilder   :  문자열 연산이 많고 단일쓰레드이거나 동기화를 고려하지 않아도 되는 경우

- System.out.println 메소드는 현업에서 절대 쓰지 말라고하는 메소드인데요. 그 이유가 무엇일까요?
    - 휘발된다.
        - System.out.println() 은 로그가 표준 출력으로 출력된다. 즉, 파일로 저장되지 않고 휘발된다는 의미이다.
          로그는 에러가 발생한 상황을 기록하고, 추후 확인하여 문제를 진단하고, 재현하고, 고치기 위해 사용된다.
          하지만 표준 출력으로 한번 출력되고 어디에도 저장되지 않으면 로그의 제 역할을 할 수 없다.
    - 에러 발생 시 추적할 수 있는 최소한의 정보가 남지 않는다.
        - System.out.println() 은 인자로 전달한 문자열만을 출력한다.
          문제가 발생한 날짜, 시각 그리고 문제의 수준, 로그가 발생한 위치 등 최소한의 정보가 기록되지 않는다는 것 이다.
    - 로그 출력 레벨을 사용할 수 없다.
        - 로컬에서 개발할 때에는 디버깅을 위한 아주 상세한 정보가 출력되어 확인할 수 있어야한다. 하지만, 프로덕션에서 동작하는 코드는
          에러/장애가 발생할 때 문제를 진단할 수 있는 정보만을 남겨야한다. 개발시에만 사용되는 정보와 문제 상황에 대한 정보가
          함께 로깅된다면 문제 해결을 위한 정작 중요한 정보를 얻기 힘들 뿐더러, 민감한 정보를 로그로 남길수도 있기 때문이다.
          또한 의미없는 로그가 쌓여 서버 용량을 차지할 수도 있다.
        - 따라서 로깅 라이브러리는 환경에 맞게(로컬 개발 환경, 개발 서버, 프로덕션 서버 등) 로그가 출력될 수 있도록 로그 출력 레벨이라는
          기능을 제공한다. 많이 사용되는 Logback 이라는 라이브러리에서는 TRACE, DEBUG, INFO, WARN, ERROR, FATAL 와
          같은 레벨을 제공한다. 하지만 System.out.println() 은 이런 기능을 제공하지 않는다. 어떤 환경에서든 동일한 로그가 출력된다.
          프로덕션에서 이런 로그를 제거하려면 코드를 일일히 제거하거나 주석처리하거나 별도의 조건문을 설정하는 등 번거로운 일들을 해야한다.
    - 성능저하의 원인이 될 수 있다.
        - System.out.println() 의 구현을 한번 살펴보자.
        - println() 은 newLine() 을 호출한다. newLine() 의 구현도 살펴보자.
        - synchronized 키워드가 붙어있다. 이때 newLine() 메소드는 임계영역(critical section)이 된다. 멀티 쓰레드 환경에서
          A 쓰레드가 newLine() 메소드를 실행하면, 메소드는 잠기게 된다. 다른 쓰레드는 A 쓰레드가 모두 사용하고 잠금을 풀어준 뒤에서야
          newLine() 메소드를 실행할 수 있다. 오버헤드가 발생하게 되는 것이다.
        - 스프링을 실행하는 톰캣은 멀티 쓰레드로 동작한다. 요청이 오면 쓰레드 풀에서 쓰레드를 하나 가져와 요청을 처리한다. 그런데,
          System.out.println() 을 여러 쓰레드가 사용하면 그만큼 위에서 이야기한 오버헤드가 발생하고 처리가 느려질 것 이다.
          따라서 실제 프로덕트의 코드에서는 System.out.println() 을 절대 사용해서는 안된다.

    - synchronized 키워드는 왜 현업에서 큰 성능 저하를 일으킬 수 있을까요?
      Blocking IO는 왜 성능을 저하시킬 수 있을까요?
      synchronized 가 Blocking IO 와 만나면 어떻게 환장의 성능하락을 만들 수 있는걸까요?
      이 두 개가 만났을 때 스레드가 어떻게 동작할지, CPU 사용률은 어떻게 될지 시뮬레이션을 해보세요.

- ArrayList 는 내부적으로 어떻게 구현되어있을까요?
    - ArrayList 는 배열을 좀 더 편하게 쓸 수 있도록 Java 에서 제공해주는 Class 입니다. 일반 배열과는 다르게 메모리가 가능한 한
      추가할 수 있고 삭제에 대해서도 해당 index 를 비워두기만 하는게 아니라 재정렬해주는 기능을 기본으로 제공해주고 있습니다.
    - ArrayList 는 새 요소를 추가하고자 할 때, capacity 가 기존 배열의 크기와 같아지면 기존 용량의 1.5배만큼 증가시키고 그 크기가 늘어난
      배열에 기존 elementData 를 copy 한다. 실제로는 정적 배열을 사용하지만, 요소가 추가될 때마다 최소 증가량을 계산하여 크기를 늘리는 방식
    - 자료를 대량으로 추가하거나 삭제하면 내부 처리 작업이 늘어나서 성능이 떨어질 수 있다.
    - add: 실제로 배열의 크기를 재산정하고 기존(old)에 있던 정보를 새로운 배열(new)에 넣는 메서드입니다.
           크기를 재산정 할때는 원래크기만큼 새로운 배열에 복사를 해야하므로 시간복잡도 O(n)을 가지며 추가할 때 O(1)
    - remove: remove 메서드를 실행하면 가장 먼저 입력받은 index 가 적절한 값인지 체크합니다. 그리고 삭제되는 Object 의 값을 가져와서
              변수에 담습니다. 그 후 arraycopy 를 이용해 삭제되는 부분 + 1 ~ 마지막까지의 영역을 삭제되는 부분의 시작점을 기준으로
              해서 옮깁니다. 그러면 삭제될 부분의 값은 다음 index 의 값으로 겹쳐서 덮여 쓰여지게 됩니다. 그리고 size 의 마지막 index 는
              size - 1의 값과 중복되기 때문에 null 처리를 하여 GC가 삭제할 수 있도록 합니다. 그 후 임시 변수에 담아두었던
              삭제된 값을 리턴합니다.
              삭제를 할때 우리는 index + 1에서 부터의 값을 index 부터 시작하게끔 복사한다는 것을 알 수 있었습니다. 그때 O(n)의
              시간복잡도를 가지며 마지막 값을 null 로 변경해줍니다. 이때는 O(1)을 가지겠죠. 삭제에 대해서는 항상
              시간복잡도 O(n)을 가진다는 것을 알 수 있습니다.

- 스레드는 왜 써야하는 것일까요? https://cbw1030.tistory.com/282,  https://www.crocus.co.kr/1510,  https://itchipmunk.tistory.com/437,  http://blog.skby.net/%EC%93%B0%EB%A0%88%EB%93%9C-thread/
    - 프로세스
        - 프로세스란
            - 프로세스는 실행중인 프로그램이다. 즉, 메모리에 올라간 상태이다.
              실행파일을 클릭했을 때, 메모리(RAM)할당이 이루어지고, 이 메모리공간으로 코드가 올라간다. 이 순간부터 이 프로그램은 '프로세스'라 불리게 된다.
        - 프로세스의 스케줄링
            - CPU 는 하나인데, 동시에 여러 프로세스가 실행되어야한다. CPU 는 여러개의 프로세스를 번갈아가면서 실행하는데  매우 고속이기 때문에
              우리 눈에는 동시에 실행되는 것처럼 보인다. 이러한 멀티프로세스 운영체제에서 프로세스의 CPU 할당 순서 및 방법을 결정짓는 것을 '스케줄링'이라 한다.
        - 프로세스의 상태변화
            - 프로세스는 Ready, Running, Blocked 상태를 지닌다. Running 상태인 프로세스는 더 우선순위가 높은 프로세스가 실행될 경우
              Ready 상태가 되고, 우선순위가 높은 프로세스가 실행된다. Blocked 상태에 있는 프로세스는 스케줄러의 관심 밖에 있어서
              스케줄러에 의해 선택이 되지 않는 프로세스이다.
        - 컨텍스트 스위칭(Context Switching)
            - CPU 내에 존재하는 레지스터들은 현재 실행중인 프로세스 관련 데이터들로 채워진다.
              실행중인 프로세스가 변경이 되면, CPU 내 레지스터들의 값이 변경되어야 하는데, 변경되기 전에 이전 프로세스가 지니고 있던
              데이터들을 어딘가에 저장해 주어어야 한다.( 이어서 실행하기 위해 ). 그리고 새로 실행되는 프로세스가 아니라면 이전에 실행될 때
              레지스터들이 지니고 있던 데이터들을 불러와서 이어서 실행해야 한다. 이 과정이 컨텍스트 스위칭이다.
              실행되는 프로세스의 변경 과정에서 발생하는 컨텍스트 스위칭은 시스템에 많은 부담을 준다.
              레지스터 개수가 많을수록, 프로세스별로 관리되어야할 데이터 종류가 많을수록 더 부담이 된다.
              컨텍스트 스위칭에 소요되는 시간을 줄이려면 저장하고 복원하는 컨텍스트 정보의 개수를 줄여주면 된다.
        - 메모리 구조 관점에서 본 프로세스와 쓰레드
            - 자식 프로세스가 생성되고 난 다음에는 부모프로세스가 가진 핸들테이블은 상속되지만 모든것(Code/data/heap/stack 영역) 이
              독립적으로 만들어진다. 이러한 메모리 구조를 지녔기에, 프로세스간에 데이터를 주고받기 위해서는
              IPC(Inter Process Communication)가 필요하다. 하지만 쓰레드를 생성하는 경우 메모리 구조는 다르다.
              프로세스가 쓰레드 A와 B를 생성한 경우 쓰레드를 생성할 때마다, 해당 쓰레드만을 위한
              ThreadStack 영역(실행 흐름의 추가를 위한 최소조건)만이 생성될 뿐, 나머지 영역(Code, Data, Heap)은
              부모 프로세스 영역을 공유하고 있다. 쓰레드마다 스택을 독립적으로 할당해준다.
    - 스레드
        - 쓰레드는 실행 흐름(절차)을 갖는 줄이다. 즉, 프로세스 내에서 실행 흐름을 의미한다. 프로세스 내의 명령어 블록으로 시작점과 종료점을 가짐.
        - 자바에서 스레드를 사용하는 이유
            - 동시에 두 가지 이상의 활동을 하기 위함이다.
            - 그리고 프로세스끼리는 정보를 주고 받을 수는 없지만, 다중 스레드 작업 시에 각 스레드끼리는 정보를 주고받을 수 있는 장점이 있다.
        - 스레드 사용 이유
            - 운영체제는 시스템 작업을 효율적으로 관리하기 위해 스레드를 이용한다.
            - 즉, 멀티 프로세스로 실행되는 작업을 멀티 스레드로 실행하게 되면 프로세스를 생성하여 자원을 할당하는 과정도 줄어들 뿐더러
              프로세스를 컨텍스트 스위칭(Context Switching)하는 것 보다 오버헤드를 더 줄일 수 있게 된다.
            - 뿐만 아니라 프로세스간의 통신 비용보다 하나의 프로세스 내에서 여러 스레드간의 통신 비용이 훨씬 적으므로 작업들 간의 통신 부담을 줄일 수 있게 된다.
            - 멀티스레드를 사용하는 큰 이유 중의 하나가 바로 다중 CPU 하드웨어를 충분히 활용하고자 하는 것이다.
        - 스레드가 프로세스보다 안좋을 때
            - 멀티 프로세스 구조에서 여러 개의 자식 프로세스 중 하나에 문제가 발생하면 자식 프로세스 하나만 죽는다 해서 다른 곳에 영향을 끼치지는 않는다.
              하지만 멀티 스레드 구조에서 자식 스레드중 하나에 문제가 생긴 경우에는 전체 프로세스가 영향을 받게 된다.(ex : thread I/O)
              그리고 멀티 스레딩을 너무 자주 사용하게 된다면 컨텍스트 스위칭의 비용이 상당히 높기 때문에 오히려 시스템 성능 저하를 초래 할 수도 있고
              메모리가 공유되기 때문에 안정성 및 보안을 좀 더 추구하는 경우에는 멀티 스레드보단 멀티 프로세싱이 더 좋다.
            - 메모리 구분이 필요할 경우에는 멀티프로세스가 유리하고, 컨텍스트 스위칭이 자주 일어나고 데이터 공유가 빈번하면 멀티 스레드를 사용하는것이 유리합니다.
        - 특징  https://jungwoong.tistory.com/45, https://olivejua-develop.tistory.com/68
            - 메모리 영역을 공유를 하기 때문에 메모리 공간과 시스템 자원 소모가 줄어들게 되며,
              멀티 프로세스와 다르게 캐시메모리를 초기화할 필요가 없기 때문에 컨텍스트 스위칭 연산이 빠릅니다.
            - 스레드간의 자원을 공유하기 때문에 동기화 문제가 발생할 수 있기 때문에 주의깊은 설계가 필요합니다.
            - 하나의 스레드가 문제가 생기면 프로세스내의 다른 스레드에도 문제가 생길 수 있습니다.
            - 쓰레드가 프로세스보다 컨텍스트 스위칭이 빠른 이유는 메모리 영역을 공유하기 때문이다. 실제로 공유되는 데이터가 있고 아닌 데이터가 있다.
            - 프로세스에서 스레드가 생성되면 운영체제는 프로세스의 주소 공간에 스레드 스택으로 사용할 영역을 예약하고
              영역의 일부만 물리적 저장소에 커밋합니다. 일반적으로 스레드를 생성하면 1MB 주소 공간으로 설정됩니다.
              스택의 메모리 크기는 지정할 수 있습니다.
            - 어떤 스레드는 기본적으로 프로그램이 시작할 때 실행됩니다. 이 스레드가 바로 ’메인 스레드’입니다. 메인 스레드는 작업을
              처리하기 위해 새로운 스레드를 생성합니다. 이러한 새 스레드는 다른 스레드와 병렬로 실행되며,
              대개 실행이 완료되면 메인 스레드와 결과를 동기화합니다.
            - 멀티스레딩은 여러 코어에서 한 번에 여러 개의 스레드를 처리하는 CPU 성능을 활용하는 프로그래밍의 한 유형입니다.
            - 이러한 멀티스레딩 방식은 여러 개의 작업이 오랫동안 실행되는 경우에 적합합니다. 하지만 일반적으로 게임 개발 코드에는
              한 번에 실행해야 할 작은 명령이 많이 들어 있습니다. 각 명령에 대해 스레드를 만들면 그 수가 너무 많아지고 각각의 수명도 짧아집니다.
              따라서 CPU 및 운영체제의 프로세싱 능력을 초과할 수 있습니다.
            - 스레드 풀을 사용하면 스레드 수명 주기 문제를 완화할 수 있습니다. 하지만 스레드 풀을 사용해도 동시에 활성화된 스레드 수가
              너무 많을 수 있습니다. CPU 코어보다 스레드 수가 더 많으면 CPU 리소스를 놓고 스레드 간에 경쟁이 벌어지고,
              이로 인해 컨텍스트 스위칭이 빈번하게 발생합니다. 컨텍스트 스위칭은 실행 도중에 스레드 상태를 저장하고 다른 스레드에 대한
              작업을 진행한 후 첫 번째 스레드를 재구성하여 나중에 계속 처리하는 프로세스입니다. 컨텍스트 스위칭은 리소스를
              매우 많이 소모하므로 가급적 사용하지 않는 것이 좋습니다.
        - 컨텍스트 스위칭이 빨라진 쓰레드와 캐쉬 적중  https://agh2o.tistory.com/12
            - 쓰레드는 공유하는 영역이 많기 때문에 컨텍스트 스위칭이 빠르다.
              캐쉬는 CPU 와 메인메모리 사이에 위치하며 CPU 에서 한번 이상 읽어들인 메모리의 데이터를 저장하고 있다가,
              CPU 가 다시 그 메모리에 저장된 데이터를 요구할 때, 메인메모리를 통하지 않고 데이터를 전달해 주는 용도이다.
              프로세스 컨텍스트 스위칭이 일어났을 경우, 공유하는 데이터가 없으므로 캐쉬가 지금껏 쌓아놓은 데이터들이 무너지고
              새로 캐쉬정보를 쌓아야 한다. 이것이 프로세스 컨텍스트 스위칭에 부담이 되는 요소이다.
              반면, 쓰레드라면 저장된 캐쉬 데이터는 쓰레드가 바뀌어도 공유하는 데이터가 있으므로 의미있다. 그러므로 컨텍스트 스위칭이 빠른 것이다.

        - 운영체제나 JVM 이 CPU 를 많이 사용하면 할수록 실제 프로그램 스레드가 사용할 수 있는 CPU 양은 줄어든다.
          컨텍스트가 변경되면서 다른 스레드를 실행하려면 해당 스레드가 사용하던 데이터가 프로세서의 캐시 메모리에 들어 있지 않을 확률도 높다.
          그러면 캐시에서 찾지 못한 내용을 다른 저장소에서 찾아와야 하기 때문에 원래 예정된 것보다 느리게 실행되는 것이다.
          대기 중인 스레드가 밀려 있다고 해도, 현재 실행 중인 스레드에게 최소한의 실행 시간을 보장해주는 정책을 취하고 있다.
          대기 상태에 들어가는 연산을 많이 사용하는 프로그램(블로킹 I/O를 사용하거나, 락 대기 시간이 길거나, 상태 변수의 값을 기다리는 등)은
          CPU 를 주로 활용하는 프로그램보다 컨텍스트 스위칭 횟수가 훨씬 많아지고, 따라서 스케줄링 부하가 늘어나면서 전체적인 처리량이 줄어든다.
          (넌블록킹 알고리즘을 사용하면 컨텍스트 스위칭에 소모되는 부하를 줄일 수 있다.)
          컨텍스트 스위칭에 필요한 비용은 프로세서상에서 5,000 ~ 10,000 클럭 사이클 또는 수 마이크로초 동안 시간을 소모한다고 알려져 있다.

        - 메모리 동기화
          메모리 배리어는 캐시를 플러시하거나 무효화하고, 하드웨어와 관련된 쓰기 버퍼를 플러시하고, 실행 파이프라인을 늦출 수도 있다.
          멀티스레드를 사용하는 큰 이유 중의 하나가 바로 다중 CPU 하드웨어를 충분히 활용하고자 하는 것이다.
          암달의 법칙에 따르면 애플리케이션 확장성은 반드시 순차적으로 실행되야만 하는 코드가 전체에서 얼마만큼의 비율이 차지하냐에 달렸다고 한다.

- 0이 들어있는 변수에 10개의 스레드가 동시에 접근해서 ++ 연산을 하면 우리 예상과 다르게 10이 나오지 않습니다. 왜 그럴까요?  https://castlejune.tistory.com/23
    - 싱글스레드 프로세스의 경우 프로세스 내에서 단 하나의 스레드만 작업하기 때문에 프로세스의 자원을 가지고 작업하는데 별문제가 없지만,
      멀티스레드 프로세스의 경우 여러 스레드가 같은 프로세스 내의 자원을 공유해서 작업하기 때문에 서로의 작업에 영향을 주게 됩니다. -> 스레드의 동기화
    - ++ 연산은 구체적으로 어떤 행위들로 이루어져 있을까요?
        메모리에서 해당 값을 가져옵니다.
        해당 값에 1을 더합니다.
        메모리에 더한 값을 덮어씌웁니다.
    - 이 문제를 해결하려면 어떻게 해야할까요?
        - JVM 은 데이터를 4byte(=32bit)단위로 처리하기 때문에, int 와 int 보다 작은 타입들은 한 번에 읽고 쓰는 것이 가능합니다.
          즉, 단 하나의 명령어로 읽거나 쓰기가 가능하다는 뜻입니다. 하나의 명령어는 더 이상 나눌 수 없는 최소의 작업단위이므로,
          작업의 중간에 다른 스레드가 끼어들 틈이 없습니다. 다만, 크기가 8byte 인 long 과 double 타입의 변수는 하나의 명령어로 값을
          읽거나 쓸수 없기 때문에, 변수의 값을 읽는 과정에 다른 스레드가 끼어들 여지가 있습니다.

        - 스레드는 실행되고 있는 CPU 메모리 영역에 데이터를 캐싱합니다.
          따라서 멀티 코어 프로세서에서 다수의 스레드가 변수 a를 공유하더라도 캐싱된(갱신) 시점에 따라 데이터가 다를 수도 있습니다.
          그리고 캐싱된 데이터가 언제 갱신되는지 정확히 알수 없습니다.

        1. 적절한 동기화 처리
            - 동기화는 배타적 실행뿐 아니라 스레드 사이의 안정적인 통신에 꼭 필요하다.
            - 스레드가 synchronized 블럭으로 들어갈 때와 나올 때, 캐시와 메모리간의 동기화가 이루어지기 때문에 값의 불일치가 해소됩니다.
        2. volatile 키워드  https://nesoy.github.io/articles/2018-06/Java-volatile  https://jronin.tistory.com/110
            - synchronized 블럭의 임계 영역은 멀티스레드 프로그램의 성능을 좌우하기 때문에 가능하면 임계영역을 최소화해서 효율적인 프로그래밍을 해야합니다.
            - 속도가 더 빠른 대안을 소개하자면 자바에서 volatile 이란 한정자로 변수의 읽기와 쓰기를 원자화 할 수 있습니다.
            - volatile 키워드를 붙이면 해당 변수를 읽어올 때 캐시가 아닌 메모리에서 직접 읽어오게 되는데 그렇기 때문에 스레드 간 안정적인 통신은 보장할 수 있습니다.
            - 매번 변수의 값을 Read 할 때마다 CPU cache 에 저장된 값이 아닌 Main Memory 에서 읽는 것입니다.
            - 주의할 점은 volatile 키워드는 변수의 읽기나 쓰기의 원자화를 보장하지만 배타적 수행과는 상관없습니다!
            - volatile 은 원자적 연산에서만 동기화 보장
            - 값을 읽고 쓰는 비-원자적 연산 작업이 하나의 스레드에서만 일어나고 다른 스레드들에서는 단지 값을 읽는 원자적 연산만 한다면
              위와 같은 문제는 발생하지 않기 때문에 volatile 키워드만으로 충분히 동기화
            - volatile(통신 동기화)만으로 동기화가 되는 상황이라면 synchronized 보다는 volatile 만으로 동기화 처리를 하는 것이 낫습니다.
              왜냐하면 배타적 실행을 위해 락을 획득하고 반환하는 비용이 발생하지 않기 때문입니다.
              만약 배타적 실행 제어가 필요하다면 synchronized 를 사용해야 합니다.
            - 간혹 synchronized 키워드와 volatile 키워드가 같이 사용되는 코드를 볼 수 있습니다.
              자바 1.5이후부터 volatile 키워드가 붙은 변수들은 컴파일 단계에서 재배치-최적화를 하지 않도록 변경되었기 때문에
              Double-checked locking 구문에서 최적화를 하지 않도록 하기 위해 volatile 를 붙이기도 합니다.
        3. Atomic 변수(java.util.concurrent.atomic)
            - 멀티쓰레드 환경에서 동기화 문제를 synchronized 키워드를 사용하여 락을 걸곤 하는데 이 키워드 없이 동기화문제를 해결하기 위해 고안된 방법입니다.
            - synchronized 는 특정 스레드가 해당 블럭 전체에 락을 걸기때문에 다른 스레드는 아무런 작업을 하지 못하고 기다리는
              상황(Blocking)이 될 수 있어서 낭비가 심합니다. 그래서 Non-Blocking 하면서 동기화 문제를 해결하기 위한 방법이 Atomic
            - java.util.concurrent.atomic 패키지에는 락 없이도(lock-free) thread-safe 한 프로그래밍을 지원하는 클래스들이 담겨 있습니다.
              성능도 더 우수하다고 알려저 있습니다.
            - volatile 은 동기화의 두 효과 중 스레드 간 통신 쪽만 지원하지만 이 패키지는 원자성(배타적 수행)까지 지원합니다.
              클래스들을 까보니 내부적으로 volatile 키워드를 내포
            - Atomic 의 동작 핵심원리는 CAS 알고리즘(Compared and Swap)   https://javaplant.tistory.com/23

        - 비-원자적 연산에서의 동기화 처리
            1. synchronized
                - 값을 변경하기 위해 읽고-저장하는 작업(비-원자적 연산)은 동시에 하나의 스레드만 처리할 수 있도록 일종의 락을 거는 방법입니다.
                  비-원자적 연산을 원자화시키는 거라고 볼 수 있습니다.
                - synchronized 은 단일 스레드만 진입하도록 하는 배타적 실행 동기화뿐만 아니라 가장 최근의 값(메인 메모리에서)을 가져오는
                  통신 동기화 기능도 같이 수행
            2. concurrent 패키지의 atomic 클래스

        - 동기화에 대한 문제를 피하는 가장 좋은 방법은 가변 데이터를 공유하지 않는 것이며 가변 데이터는 단일 스레드에서만 사용하는 것이 좋다.
        - 가변 데이터를 단일 스레드에서만 사용한다면 문서에 남겨 유지보수 정책에서도 지켜지는것이 중요하다.
        - 멀티 스레드 환경에서 한 스레드가 데이터를 수정한 후에 다른 스레드에 공유할 때는 해당 객체에서 공유하는 부분만 동기화해도 된다.
        - 여러 스레드가 가변 데이터를 공유한다면 그 데이터를 읽고 쓰는 메서드 모두에 반드시 synchronized 키워드를 붙이거나 가변 데이터에 atomic 변수를 사용한다.
        - 배타적 실행 (한번에 한스레드) 동작이 필요없고, 스레드 간 최신데이터만 읽는 거로도 충분하면 가변 변수에 volatile 키워드만으로도 동기화가 가능하다.

- 자바에서 동시성과 관련된 예약어를 모두 말씀해주세요.

- Blocking IO와 Non-Blocking IO 의 차이를 말씀해주세요.  https://junghyungil.tistory.com/131  https://velog.io/@octo__/BlockingNon-Blocking-IO-IO-%EC%9D%B4%EB%B2%A4%ED%8A%B8-%ED%86%B5%EC%A7%80-%EB%AA%A8%EB%8D%B8
                                                     https://luv-n-interest.tistory.com/1121
    - Blocking IO 가 일어나면 스레드에는 무슨 일이 생길까요?
        - I/O 작업이 blocking 방식으로 구현되면 하나의 클라이언트가 I/O 작업을 진행하면 해당 쓰레드가 진행하는 작업을 중지하게 된다.
          영향을 미치지 않게 하기 위해서 클라이언트 별로 Thread 를 만들어 연결시켜주어야 한다. Thread 가 많아지면 시간 할당량은 작아진다.
          시간할당량이 작으면 동시에 수행되는 느낌을 가질 수 있다.
        - Thread 수는 접속자 수가 많아질 수록 Thread 수도 많아지게 된다. Thread 가 많으면 CPU 의 Context Switching 및
          interrupt 횟수와 오버헤드 증가하게 된다. 이러한 것들이 발생할 때 cpu 는 일하지 못한다. 때문에, 실제 작업하는 양에 비하여 훨씬
          비효율적으로 동작하게 될 것이다. 즉, 성능에 악영향을 줄 수 있다.
        - Non-Blocking 방식으로 이 문제를 해결
        - Non-Blocking I/O은 I/O 작업을 진행하는 동안 쓰레드의 작업을 중단시키지 않는다. 쓰레드가 커널에게 I/O를 요청하는 함수를 호출하면,
          함수는 I/O를 요청한 다음 진행상황과 상관없이 바로 결과를 반환한다.
        - I/O는 스트림으로 단 반향으로만 가능하지만, NIO 는 Channels 과 Buffers 를 이용해 양방향으로 가능하다. 또 Selectors 가 있다.
            - Channels
                - 일반적인 NIO 의 I/O는 채널에서 시작된다. Java NIO 채널은 몇 가지 차이점을 제외하고 스트림과 유사하다.
                - 채널은 항상 데이터를 버퍼로 읽고 버퍼는 데이터를 채널에 쓴다.
                - 채널을 읽고 쓸 수 있다. 스트림은 일반적으로 단방향 (읽기 또는 쓰기)이다.
                - 채널은 비동기 적으로 읽고 쓸 수 있다. ( ServerSocketChannel 이나 SocketChannel 의 경우는 Selector 를 활용해 Non-Blocking 프로그래밍이 가능하다.)
            - Buffers
                - Java NIO 버퍼는 NIO 채널과 상호 작용할 때 사용된다. 버퍼는 기본적으로 데이터를 쓸 수있는 메모리 블록이며
                  나중에 다시 읽을 수 있다. 이 메모리 블록은 NIO Buffer 객체로 래핑되어 메모리 블록으로 작업하기 쉽게하는 일련의 메서드를 제공한다.
            - Channels 과 Buffers 를 이용한 Non-Blocking I/O - NIO
                - 자바 NIO 에서는 non-blocking IO를 사용할 수 있다. 예를 들면,
                  하나의 스레드는 버퍼에 데이터를 읽도록 채널에 요청할 수 있다.
                  채널이 버퍼로 데이터를 읽는 동안 스레드는 다른 작업을 수행할 수 있다.
                  데이터가 채널에서 버퍼로 읽어지면, 스레드는 해당 버퍼를 이용한 processing(처리)를 계속 할 수 있다.
                  데이터를 채널에 쓰는 경우도 non-blocking 이 가능하다.
            - Selectors
                - 셀렉터를 사용하면 하나의 스레드가 여러 채널을 처리(handle)할 수 있다.
                - 셀렉터는 사용을 위해 하나 이상의 채널을 셀렉터에 등록하고 select() 메서드를 호출해 등록 된 채널 중 이벤트 준비가 완료된 하나 이상의 채널이 생길 때까지 봉쇄(block)된다.
                - 메서드가 반환(return)되면 스레드는 채널에 준비 완료된 이벤트를 처리할 수 있다.
                  즉, 하나의 스레드에서 여러 채널을 관리할 수 있으므로 여러 네트워크 연결을 관리할 수 있다. (SocketChannel, ServerSocketChannel)
        - 커널 수준의 쓰레드 vs 사용자 수준의 쓰레드
            - 커널 수준의 쓰레드
                - 커널 수준 스레드는 커널 레벨에서 생성되는 스레드이다.
                - 운영체제 시스템 내에서 생성되어 동작하는 스레드로, 커널이 직접 관리한다.
                - 그런데 커널 수준에서는 프로세스가 주기억 장치에 여러 개가 적재되어 CPU 할당을 기다리며 동작한다.
                - CPU 에서 인터럽트 발생으로 현재 작업 중인 프로세스가 Block 되고 다른 프로세스로 변경할 때,
                  CPU 내 재배치 레지스터에 다음에 실행할 프로세스 정보들로 교체를 하고 캐시를 비운다. 이것을 컨텍스트 스위칭이라고 한다.
                - 이 컨텍스트 스위칭이 일어날 때는 CPU 가 일을 못한다. 그래서 이게 자주 일어나면 성능에 영향이 발생하게 되는 단점이 있다.
                - 하지만 커널이 직접 관리하므로 특정 스레드가 Block 이 되어도 다른 스레드들은 독립적으로 일을 할 수 있다.
            - 사용자 수준의 쓰레드
                - 쓰레드 패키지를 사용자 영역에 두고 운영체제 커널은 단일 프로세스만을 관리한다.
                - 쓰레드 패키지를 런타임 시스템에서 사용한다.
                - 운영체제를 사용하는 입장에서는 런타임 시스템도 하나의 프로세스로 인식한다.
                - 쓰레드를 운영하지 않는 운영체제제에서 실행할 수 있으므로 이식성이 뛰어나다.
                - 즉, 입출력 인터럽트가 발생하면 커널은 '사용자 모드'가 되어서 사용자 수준 스레드의 응답을 기다린다.
                  사용자 수준 스레드의 응답이 오면 다시 '커널 모드'로 변환되어 이어서 커널 스레드가 일 처리를 하게 되는 것이다.
                - 컨텍스트 스위칭이 발생하지 않는다.
            -> Blocking I/O가 커널 수준의 쓰레드, Non-Blocking NIO 가 사용자 수준의 쓰레드라고 보면 될 것 같다.
        - 정리
            - Blocking I/O는 하나의 호출마다 Thread 를 생성한다. 그에 따른 컨텍스트 스위칭이 발생하기 때문에 성능상 단점이 있다.
            - Non-Blocking IO는 요청을 받는 Thread 는 오직 하나다. Thread 내부에서 채널과 버퍼를 이용하여 Non-Blocking 방식으로 진행한다.
              그래서 컨텍스트 스위칭이 발생하지 않는다.
            - 위에서 말한 사용자 수준 스레드 관점에서 봤을 때, Context-switching 은 OS 단에서 처리하는데 이것을 사용자(개발자)가
              직접 처리한다는 개념에서 최적화 시킬 수 있다는 장점이 있다. 직접 처리한다는 것은 단일 쓰레드의 내부로 NIO 의 채널과 버퍼를 이용해서
            - 하지만 요청이 적다면, Blocking I/O가 더 좋다. 호출마다 thread 를 생성하니 요청이 적은 서비스에는 최적의 성능을 낼 수 있다.
              cpu 코어 갯수많큼 쓰레드를 생성하는게 최적이다. (병렬 작업의 장점)
            - I/O의 요청이 많아질 때 생기는 성능상의 이유로, 많은 요청을 해결하기 위해 자바 1.4에서 NIO 가 나왔고,
              NIO 는 대용량 트레픽 처리를 위해 꼭 알아야 하는 개념

        - NIO  https://deftkang.tistory.com/24
            일반적으로 네트워크의 속도는 컴퓨터의 CPU, 메모리, 심지어 디스크의 속도와 비교해도 매우 느리다. 이러한 상황에서 나오는 현상중
            상대적으로 느린 네트워크를 엄청나게 빠른 CPU 가 기다리는 것이다. CPU 가 느린 네트워크를 기다리지 않고 네트워크보다 앞서
            달리게 하기 위한 전통적인 자바의 해결 방안은 버퍼링과 멀티스레드를 결합하는 것이다. 다수의 스레드가 동시에 다수의
            서로 다른 연결을 통해 보낼 데이터를 생성한다. 그리고 네트워크가 데이터를 보낼 준비가 될 때까지 해당 데이터들을 버퍼에 저장해 둔다.
            그러나 멀티 스레드를 생성할 때 드는 오버헤드와 스레드 전환 시 발생하는 오버헤드를 무시할 수 없다. 그리고 각각의 스레드는
            약 1메가 바이트의 메모리리를 여분으로 필요로 한다. 초당 수천 개의 요청을 처리하는 대규모 서버 환경에서는 스레드가 사용하는
            여분의 메모리와 다양한 오버헤드로 인해 연결마다 스레드를 할당하는 것이 쉽지 않다. 그래서 하나의 스레드가 다수의 연결을 담당하고,
            데이터를 수신할 준비가 된 연결을 골라내서 처리하고, 그리고 다시 준비된 다음 연결을 골라내는 방법을 반복한다면 훨씬 더 빠를 것이다.
            이러한 기능을 java.nio 패키지 에서 제공한다.
        - IO와 NIO 의 차이점
            - IO는 입력 스트림과 출력 스트림이 구분 되어 입/출력 별도의 생성이 필요하다.  또 동기(synchronous) 방식이기 때문에
              입력과 출력이 다 될때까지 스레드는 멈춰 있어야 한다. 이것을 블로킹이라고 하는데 interrupt 로 블로킹(Blocking)을
              빠져 나올 수 없다. 블로킹을 빠져 나오는 유일한 방법은 스트림을 닫는 것이다. 반면 NIO 는 양방향 입출력이 가능하므로
              하나만 생성하면 된다. 또 NIO 는 블로킹(Blocking)과 넌블로킹(Non-Blocking)을 지원하는데 넌블로킹 방식으로 입출력 작업시
              스레드가 블로킹 되지 않는다. 또 NIO 블로킹은 스레드 interrupt 로 인해 빠져 나오는 것이 가능하다.
            - IO
                - 스트림 방식
                - 넌버퍼
                - 동기 방식
                - 블로킹 방식
            - NIO
                - 채널 방식
                - 버퍼
                - 동기/비동기 방식 모두 지원
                - 블로킹/넌블로킹 방식 모두 지원
        - NIO 패키지 핵심개념
            1. 채널(Channel)
                - 채널은 파일, 소켓, 데이터그램 등과 같은 다양한 I/O 소스로부터 데이터 블록을 버퍼로 쓰거나 읽어 온다.
                - 비동기 읽기/쓰기를 지원하는 스트림과 같은 기술이다.
            2. 버퍼(Buffer)
                - nio(new input/output) 에서는 모든 I/O가 버퍼링된다. 게다가 버퍼는 새로운 I/O API의 기초를 이루고 있다.
                - 데이터를 입출력 스트림으로 쓰거나 읽지 않고 대신 버퍼에 일시적으로 저장하여 쓰고 읽는다.
                - 채널과 함께 동작한다.
            3. 셀렉터(Selector)
                - 싱글 스레드에서 다중채널을 처리 하기 위한 기술이다. 즉 준비된 채널을 선택함으로써 읽고 쓸 때 블록하지 않아도 된다.
                - 애플리케이션에서 싱글 스레드로 low-traffic 연결을 처리하는 경우 유용하다.

    - 스레드가 멈춰있는 동안 CPU 는 어떻게 될까요?
    - CPU 가 쉬는 것을 막으려면 어떻게 해야할까요?
    - 스레드를 늘리면 단점이 무엇일까요?
        - 이 것이 Tomcat 이 스레드를 수 백개씩 띄우는 이유입니다.
          Tomcat 은 일반적으로 Blocking 방식이기 때문에 스레드 1개당 요청 1개를 처리할 수 밖에 없습니다.
    - Non-Blocking IO는 CPU 활용률이 어떨까요?
        - Spring WebFlux 와 Netty
            - Spring WebFlux  https://alwayspr.tistory.com/44
                - I/O
                    - 사용자가 I/O 요청을 할 때 CPU 가 I/O Controller 에 요청을 하고 I/O Controller 가 파일을 다 가져오면 그것을
                      Memory 에 적재시키고 CPU 에게 완료되었다고 알려준다. 즉 큰 그림은 CPU -> I/O Controller -> CPU 의 형태이다.
                      핵심은 CPU 가 I/O를 직접 가져오는 것이 아니라, 작은 CPU 라고 불리는 I/O Controller 가 수행한다는 이야기이다.
                      좀 더 나아가면 작업을 단순히 위임시키고 작업이 완료되는 동안에는 다른 일을 수행할 수 있다는 말이다.
                      이러한 예처럼 I/O를 처리하는데 몇 가지 방법이 있다.
                - Blocking I/O
                    - Application 에서 I/O 요청을 한 후 완료되기 전까지는 Application 이 Block 이 되어 다른 작업을 수행할 수 없다.
                      이는 해당 자원이 효율적으로 사용되지 못하고 있음을 의미한다.
                    - 그러나 생각을 해보면 여러분들의 Application 들은 Blocking 방식임에도 불구하고 마치 Block 이 안된듯이
                      동작하는 것처럼 보인다. 이것은 여러분들이 Single Thread 를 기반으로 하는 것이 아닌 Multi Thread 를 기반으로
                      동작하기 때문이다. Block 되는 순간 다른 Thread 가 동작함으로써 Block 의 문제를 해소하였다.
                      그러나 Thread 간의 전환(Context Switching)에 드는 비용이 존재하므로 여러 개의 I/O를 처리하기 위해
                      여러 개의 Thread 를 사용하는 것은 비효율적으로 보인다.
                - Synchronous Non-Blocking I/O
                    - Application 에서 I/O를 요청 후 바로 return 되어 다른 작업을 수행하다가 특정 시간에 데이터가 준비가 다되었는지
                      상태를 확인한다. 데이터의 준비가 끝날 때까지 틈틈이 확인을 하다가 완료가 되었으면 종료된다.
                      여기서 주기적으로 체크하는 방식을 폴링(Polling) 이라고 한다. 그러나 이러한 방식은 작업이 완료되기 전까지
                      주기적으로 호출하기 때문에 불필요하게 자원을 사용하게 된다.
                - Asynchronous Non-blocking I/O
                    - I/O 요청을 한 후 Non-Blocking I/O와 마찬가지고 즉시 리턴된다. 허나, 데이터 준비가 완료되면 이벤트가 발생하여
                      알려주거나, 미리 등록해놓은 callback 을 통해서 이후 작업이 진행된다. 이전 두 I/O의 문제였던
                      Blocking 이나 Polling 이 없기 때문에 자원을 보다 더 효율적으로 사용할 수 있다.
                - Event-Driven
                    - Event-Driven 을 토대로 많은 프레임워크와 라이브러리가 발전하고 있다. 예) Spring WebFlux, Node.js, Vert.x 등
                    - Event-Driven Programming 은 프로그램 실행 흐름이 이벤트
                      (ex : 마우스 클릭, 키 누르기 또는 다른 프로그램의 메시지와 같은 사용자 작업)에 의해 결정되는 프로그래밍 패러다임이다.
                      Event 가 발생할 때 이를 감지하고 적합한 이벤트 핸들러를 사용하여 이벤트를 처리하도록 설계됐다. 순차적으로 진행되는
                      과거의 프로그래밍 방식과는 달리 유저에 의해 종잡을 수 없이 진행되는 GUI(Graphical User Interface)가
                      발전됨에 따라 Event-Driven 방식은 더욱더 많이 쓰이게 되었다.
                - Spring Framework
                    - Spring 은 Reactive Stack 과 Servlet Stack 두 가지 형태를 제공한다. 또한 Reactive Stack 은
                      non-blocking I/O를 이용해서 많은 양의 동시성 연결을 다룰 수 있다고 한다. 과거로 돌아가서 Servlet Stack 의
                      문제점을 파악하고 이를 어떻게 Reactive Stack 으로 해결했는지 알아보자.
                - Spring MVC
                    - 위 그림처럼 유저들로부터 HTTP 요청이 들어올 때 요청들은 Queue 를 통하게 된다. Thread pool 이
                      수용할 수 있는 수(thread pool size)의 요청까지만 동시적으로 작업이 처리되고 만약 넘게 된다면 큐에서 대기하게 된다.
                      즉 하나의 요청은 하나의 Thread 를 요구한다. (one request per thread model)
                    - Thread pool 은 다음과 같다. Thread 를 생성하는 비용이 크기 때문에 미리 생성하여 재사용함으로써 효율적으로 사용한다.
                      그렇다고 과도하게 많은 Thread 를 생성하는 것이 아니라 서버 성능에 맞게 Thread 의 최대 수치를 제한시킨다.
                      참고로 tomcat default thread size 는 200이다.
                    - 그런데 만약 대량의 트래픽이 들어와 thread pool size 를 지속적으로 초과하게 된다면 어떻게 될까?
                    - 설정해놓은 thread pool size 를 넘게 되면 위 그림처럼 작업이 처리될 때까지 Queue 에서 계속해서 기다려야 한다.
                      그래서 전체의 대기시간이 늘어난다. 이런 현상을 Thread pool hell 이라고 한다.
                    - Thread pool 이 감당할 수 있을 때까진 빠른 처리속도를 보이지만, 넘는 순간부터는 지연시간이 급격하게 늘어난다.
                    - 특수한 경우를 제외하면 DB, Network 등의 I/O가 일어나는 부분에서 아마 시간을 많이 소비했을 것이다.
                    - 설명했듯이 I/O 작업은 CPU 가 관여하지 않는다. I/O Controller 가 데이터를 읽어오고 이를 전달받을 뿐이다.
                      위에서 I/O를 처리하는 3가지 방식을 소개했는데 가장 효율이 좋은 방법은 마지막에 설명한
                      Asynchronous Non-blocking I/O 이라고 하였다. Blocking 방식은 I/O Controller 가 데이터를 읽는 동안 CPU 가
                      아무 일도 할 수가 없고, Non-Blocking 방식은 polling 때문에 불필요하게 CPU 를 소비한다고 했다.
                      Spring 에서도 Non-blocking I/O를 이용해서 효율적으로 작업을 처리할 수 있는 방법을 제공한다. 그 수단이 WebFlux 이다.
                - Spring WebFlux
                    - 사용자들에 의해 요청이 들어오면 Event Loop 를 통해서 작업이 처리가 된다. one request per thread model 과의
                      차이점은 다수의 요청을 적은 Thread 로도 커버할 수 있다. worker thread default size 는 서버의 core 개수로
                      설정이 되어있다. 즉 서버의 core 가 4개라면 worker thread 는 4개라는 말이며 이 적은 Thread 를 통해서도
                      traffic 을 감당할 수 있다. 위에서 하나의 Thread 로 3초가 걸리는 API 1000개를 호출했음에도 4초밖에 안 걸렸다는 걸
                      상기시키면 이해에 도움이 될 것이다. 또한 비슷한 Architecture 를 가진 Node.js가 이미 증명을 하고 있다.
                    - 이렇듯 Non Blocking 방식을 활용하면 좀 더 효율적으로 I/O를 제어할 수 있고 성능에도 좋은 영향을 미친다.
                      특히나 유행하는 MSA 에서는 수많은 Microservice 가 거미줄처럼 서로를 네트워크를 통해서 호출하고 있다.
                      즉 많은 수의 Network I/O가 발생할 텐데 이를 Non Blocking I/O를 통해 좀 더 성능을 끌어올릴 수 있다.
                    - 그러나 물론 제한된 점이 있다. WebFlux 로 성능을 최대치로 끌어올리려면 모든 I/O 작업이 Non Blocking 기반으로
                      동작해야 된다. Blocking 이 되는 곳이 있다면 안 하느니만 못한 상황이 되어버린다.
                      예를 들어 멀티코어로 가정을 해보자. 그럼 처리할 수 있는 Thread 는 2개인데 Blocking 이 걸리는 API 를 열명 이서
                      동시에 호출한다면 결국엔 Spring MVC 처럼 8명이 I/O 작업이 끝날 때까지 기다려야 하는 구조가 되어버리기 때문이다.

                    - Java 진영에는 아쉽게도 DB connection 을 non-blocking 으로 지원하는 라이브러리가 널리 보급되어 잘 사용되지는 않고 있다.
                      다만 R2DBC 처럼 개발이 진행 중인 라이브러리, 최근에 release 된 jasync sql 등이 있으며, MongoDB, Redis 등의 NoSQL 은 지원중이다.
                    - 또한 소수의 Thread 에 의해서 수많은 요청을 처리하고, 순서대로 작업이 처리되는 것이 아니라 Event 에 기반하여
                      실타래가 엉킨 것처럼 작업이 처리되기 때문에 트래킹 하기에 힘이 들다는 문제가 있다.

                    - 그렇다면 성능이 좋으니 무조건 WebFlux 를 사용해야 할까?
                        - 위 그림은 Spring MVC 나 Spring WebFlux 둘 다 성능이 동일한 구간이 있다. 서버의 성능이 좋으면 좋아질수록
                          해당 구간은 더 늘어날 것이다. 그렇기에 만약 여러분의 환경이 해당 구간이라면 굳이 사용할 필요가 없다.
                          또한 Spring Document 에서는 동기 방식이 코드 작성, 이해, 디버깅하기 더 쉽다고 한다. 이 말은 즉 높은 생산성을
                          가진다는 말과 같은 것으로 보인다. 그렇기에 이해타산을 잘 따져서 선택해야 할 필요가 있다.
                        - 그리고 우리는 이제 왜 성능이 동일한 구간이 생기는 지를 알 수 있다. 저 구간은 바로 Thread Pool 이
                          감당할 수 있을 정도의 요청이었기에 비동기적으로 잘 수행하다가 이후에는 Queue 에 쌓여 점점 성능이 느려졌던 것이다.
                        -> 'Spring WebFlux 는 어떻게 적은 리소스로 많은 트래픽을 감당할까?'란 궁금증을 시작으로 여기까지 왔다.
                           이에 대한 답은 I/O를 Non Blocking 을 이용하여 잘 사용하는 것과 Request 를 Event-Driven 을 통해서
                           효율적으로 처리하기 때문에 가능하다.

- Serializable 은 무엇일까요?  https://www.slideshare.net/sunnykwak90/java-serialization-46382579
    - 직렬화 기술 이해
        - 직렬화란 무엇인가?
            - 직렬화는 객체의 상태 혹은 데이터 구조를 기록할 수 있는 포맷
              (예를 들면 파일 또는 메모리 버퍼, 네트워크 연결 링크를 통해 전송될 수 있는 형태) 으로 변환.
        - 직렬화는 왜 중요한가?
            - 거의 모든 소프트웨어는 네트워크를 통해 데이터를 주고 받으며, 프로그램을 구현하는데 필요한 기반 기술 중에서 빼놓을 수 없게 됨.
            - 직렬화는 네트워크 의존성이 높은 소프트웨어일 경우, 전체 성능을 좌우할 수도 있는 중요한 기술이다.
        - 직렬화 적용 분야
            - 파일 저장소 (File storage)
                - 프로그램 실행 중에 생성된 데이터를 영구 저장소(파일 시스템) 등에 저장한 후, 이후에 프로그램이 다시 실행되었을 때 저장된
                  데이터를 메모리 상에 객체 형태로 복구해 사용한다.
            - 네트워크 통신
                - 네트워크 상에 떨어져 있는 프로그램 간에 데이터를 주고 받기 위해 데이터를 직렬화한 후, 패킷에 담아 전송
            - 데이터베이스
                - 복잡한 형태의 객체를 데이터베이스에 저장할 때 직렬화된 문자열 형태로 테이블의 칼럼에 저장하기도 한다.
            - 웹 환경
                - 웹 서버에서 브라우저(클라이언트)로 구조화된 데이터를 전송할 때 직렬화한 후 JSON 형식 등 전달하는 방식이 점차 많이 사용됨
        - 직렬화 기법 선택 시 고려할 점
            - 단순성(simple)
                - 사용하기가 복잡하지 않아야 한다.
            - 경량(compact)
                - 프레임워크(혹은 라이브러리)의 규모가 작아야 한다.
            - 유연성(flexible)
                - 다양한 데이터 타입을 직렬화할 수 있어야 한다.
            - 버전지원(versioning)
                - 객체의 데이터 구조는 설계 및 개발, 나아가 유지보수 단계에서 변화될 수 있다.
            - 속도(fast)
                - 처리 속도가 빠르면 빠를수록 좋다.
            - 확장성(scalable)
                - 복잡하거나, 거대한 형태의 데이터를 직렬화할 수 있어야 한다.
        - 직렬화 데이터 형식
            - Binary
                - 메모리에 저장된 데이터를 최소한의 가공 혹은 가공 없이 바이트의 연속된 형태로 저장하는 방식
            - JSON(JavaScript Object Notation)
                - 텍스트 형식이므로 사람과 기계 모두 읽기 가능하다. 다양한 프로그래밍 언어에서 읽고 쓸 수 있기 때문에 널리 사용됨
            - XML(Extensible Markup Language)
                - 텍스트 형식이며, JSON 에 비해 복잡하다. JSON 에 대해 가지는 장점은 스키마를 적용할 수 있고 무결성 검사가 가능하다.
            - YAML(YAML Ain't Markup Language)
                - XML 에 비해 사람이 읽고 쓰기 쉽도록 고안된 마크업 언어이다. 문법이 상대적으로 단순하고, 가독성이 높게 설계되어 있다.
        - 왜 성능이 중요한가?
            - CPU 비용
                - 메모리에 존재하는 바이너리 형태의 객체를 디스크 등에 저장할 수 있는 형태(텍스트 등)로 저장하기 위해서는 변환 처리 과정이
                  필요하며, 반대의 처리 또한 필요하다.
            - 메모리 비용
                - 변환 작업을 수행하는 과정에서 임시 버퍼(temporary buffer)를 할당하고, 네트워크를 통한 송수신 과정에서 스트림 처리 등에
                  따른 공간 할당이 필요하다.
            - 네트워크 비용
                - 직렬화를 수행하는 대다수의 프로그램 혹은 시스템은 네트워크를 통해 데이터를 주고 받게 된다. 네트워크 송수신에 있어서 패킷의
                  크기가 커질수록 전체 성능은 떨어진다.

    - 직렬화 프레임워크
        - JDK 의 Serializable 인터페이스
            - 프로그래밍하기 가장 쉽고, Serializable 인터페이스를 이용해 별도의 라이브러리 없이 즉시 사용할 수 있다.
            - 클래스를 릴리즈한 후에는 구현을 변경하기 어려워 유연성을 감소시킨다.
            - C++, 파이썬 등 다른 언어로 구현된 프로그램과 데이터를 교환할 수 없다.
            - 기본 연산자의 취약점으로 인해 불변 값이 손상되거나, 비정상적인 접근이 발생할 수 있다. (invariant corruption and illegal access)
            - 커스터마이징이 불가능하고, 소스 코드를 수정할 수 있어야 한다.
        - Java externalization (직렬화 코드를 직접 구현)
            - 객체를 저장 및 복구하는 Externalization 인터페이스를 구현해 직접 직렬화를 구현한다.
            - 인스턴스의 컨텐츠를 저장하고 복구하는 역할을 수행하는 클래스를 구현해야 한다.
            - 클래스의 구조가 변경될 때 마다, 읽고 쓰는 코드를 수정해야 한다.
        - Google GSON
            - 자바 객체를 JSON 으로 변환하거나 반대의 작업을 수행하는 자바 라이브러리.
            - 직렬화된 객체의 소스 코드를 필요로 하지 않는다.
            - 커스텀 표현을 지원한다.
        - Jackson JSON
            - 고성능, 인공공학적 JSON 프로세서 자바 라이브러리
            - 광범위한 커스터마이징 툴 지원
            - 혼합 어노테이션
            - 실체화된 인터페이스
            - 다양한 데이터 포맷 : JSON, CSV, Smile(binary JSON), XML, YAML
        - BSON for Jackson
            - 바이너리 인코딩된 JSON
            - 몽고 DB 의 주된 데이터 교환 포맷
            - 확장 프로그램 작성 가능
        - Protocol Buffers
            - 구조적인 데이터를 확장 가능하며 효율적인 포맷을 변환하는 방법 제공
            - 구글 내부에서 대부분의 내부 RPC 프로토콜과 파일 포멧에 Protocol Buffers 를 사용 중.
            - Java, C++, Python 지원
        - Kryo
            - 빠르고 효율적인 객체 그래프 직렬화 자바 프레임워크
            - 구글 코드 상의 오픈 소스 프로젝트
            - 자동화된 깊고 얕은 복사/복제
            - 소스 클래스에 대한 코드 작성 요건이 거의 없음

- GC란 무엇이고, 왜 써야할까요?
    * Java Garbage Collection  https://d2.naver.com/helloworld/1329
    * Garbage Collection 모니터링 방법  https://d2.naver.com/helloworld/6043
    * Garbage Collection 튜닝  https://d2.naver.com/helloworld/37111

    - 개발자가 GC 튜닝을 하는 궁극적인 목표는 무엇일까요?
        - GC 튜닝을 꼭 해야 할까?
            - GC 튜닝이 필요 없다는 이야기는 운영 중인 Java 기반 시스템의 옵션과 동작이 다음과 같다는 의미이다.
                - -Xms 옵션과 -Xmx 옵션으로 메모리 크기를 지정했다.
                - server 옵션이 포함되어 있다.
                - 시스템에 Timeout 로그와 같은 로그가 남지 않는다.
            - 다시 말하면, 메모리 크기도 지정하지 않고 Timeout 로그가 수도 없이 출력된다면 여러분의 시스템에서 GC 튜닝을 하는 것이 좋다.
            - 그런데 한 가지 꼭 명심해야 하는 점이 있다. GC 튜닝은 가장 마지막에 하는 작업이라는 것이다.

            - GC 튜닝을 하는 이유가 무엇인지 근본적인 원인을 생각해 보자. Java 에서 생성된 객체는 가비지 컬렉터(Garbage Collector)가
              처리해서 지운다. 생성된 객체가 많으면 많을수록 가비지 컬렉터가 가 처리해야 하는 대상도 많아지고, GC를 수행하는 횟수도 증가한다.
              즉, 여러분이 운영하고 만드는 시스템이 GC를 적게 하도록 하려면 객체 생성을 줄이는 작업을 먼저 해야 한다.

            - String 대신 StringBuilder 나 StringBuffer 를 사용하는 것을 생활화하는 것부터가 시작이라고 보면 된다. 그리고,
              로그를 최대한 적게 쌓도록 하는 것이 좋다. 하지만 어쩔 수 없는 현실도 있다. 경험상 XML 과 JSON 파싱은 메모리를 가장 많이 사용한다.
              아무리 String 을 최대한 사용 안 하고 Log 처리를 잘 하더라도, 10~100 MB 짜리 XML 이나 JSON 를 파싱하면 엄청난
              임시 메모리를 사용한다. 그렇다고 XML 과 JSON 을 사용하지 않기는 어렵다.

            - 만약 애플리케이션 메모리 사용도 튜닝을 많이 해서 어느 정도 만족할 만한 상황이 되었다면, 본격적으로 GC 튜닝을 시작하면 된다.
              필자는 GC 튜닝의 목적을 두 가지로 나눈다. Old 영역으로 넘어가는 객체의 수를 최소화하는 것과 Full GC의 실행 시간을 줄이는 것이다.

    - G1GC 부터는 GC 튜닝에 크게 손이 가진 않는데, G1GC는 어떻게 만들었길래 개발자가 튜닝을 이전보다 덜 해도 되는걸까요?
    - 리전으로 구성된 구조가 왜 튜닝의 수고를 덜어주는걸까요?
        * https://imp51.tistory.com/entry/G1-GC-Garbage-First-Garbage-Collector-Tuning
        * https://steady-coding.tistory.com/590

        - Java process 엔진이 대용량의 실시간 처리를 요구할 때, 성능은 JVM 의 GC 시간에 의존적일 수 밖에 없다. 특히 64bit 환경에서는
          메모리 제약 사항이 없어졌다고 볼 수 있기 때문에 large heap memory 를 cleaning 하는 시간을 단축하는 것이 전체 성능을
          개선하는 중요 key 라고 할 수 있다. 전통적인 Serial, Parallel 그리고 CMS 로는 이 성능을 충족하기에는 매우 어려운 것이 현실이다.
          그렇다고 사용 JVM 인 azul 을 쓰기에도 비용의 제약사항이 있다.
        - Java 9 버전부터 기본 GC 방식으로 채택되었다.
        - 전통적인 Garbage Collector(Serial, Parallel 및 CMS)는 세개의 메모리 영역의 구조를 갖는데 비해 G1은 다른 접근 방식을 갖는다.
          G1 GC의 경우 Heap 은 같은 크기의 heap region 으로 분활하며,
          이전 Garbage Collector 와 마찬가지로 특정 region 별로 역할을 부여하여 특정한 object 만이 거주하도록 하였다.
        - 전체 Old Generation 혹은 Young Generation 통째로 Compaction 을 할 필요 없고,
          해당 Generation 의 일부분 Region 에 대해서만 Compaction 을 하면 된다.
        - Garbage 로 가득찬 영역을 빠르게 회수하여 빈 공간을 확보하므로 GC 빈도가 줄어든다.
        - 더 알아보면 좋을 GC의 종류 : ZGC, Shenandoah

- 잘 운영하고 있던 어플리케이션이 갑자기 Out of Memory Error(OOM)를 내며 프로세스가 종료되었습니다. 어떻게 대처해볼 수 있을까요?
    * https://baek-kim-dev.site/53



- 서비스를 운영하면 모니터링을 해야할 일이 많은데 어떤 툴들을 사용해볼 수 있을까요?

- JIT 컴파일러란 무엇이고, 이것은 왜 필요할까요?

- 힙에 메모리를 할당하는 과정에서 어떤 일들이 벌어지나요?

- printStackTrace()를 사용하면 안되는 이유
    1. 오류 출력이 실제로 어디로 가는지 알 수 없다.
        System.err 는 System.setErr()를 통해 변경될 수 있으므로 이 오류가 어디에 출력되는 것인지 알 수 없다.
    2. 많은 오버헤드가 발생한다.
        내부에서 동기화를 위한 synchronized, Reflection 호출 등 많은 오버헤드가 발생한다.
    3. 보존 정책을 설정할 수 없다.
        보존 정책을 설정할 수 없으므로 기본적으로 Log 가 Application 생명주기와 함께한다.
    4. 보안성이 떨어진다
        StackTrace 를 통해 메서드 내부 동작 구조가 노출되기 때문에 보안성이 떨어지므로 외부에 노출해선 안된다.

*** https://steady-coding.tistory.com/576

- RestTemplate

* 프로세스와 스레드

A : 다람쥐님, 프로세스와 스레드는 각각 무엇이고 어떤 차이점이 있을까요?
프로세스는 실행 중인 하나의 애플리케이션입니다.
운영체제로부터 실행에 필요한 메모리를 할당받아 애플리케이션의 코드를 실행합니다.
필요한 메모리 영역은 프로그램의 코드를 저장하는 Text 영역, 전역 정적 변수들을 저장하는 Data, 지역 변수들을 저장할 Stack, 동적 메모리 할당을 받을 Heap 영역입니다.

운영체제에서 각 프로그램들은 동시에 실행할 수 있도록 멀티 프로세스로 동작합니다.
이는 CPU 자원을 잘게 쪼갠 시간 내에 점유한다는 뜻입니다.
하나의 프로세스가 CPU 자원을 점유하려는 순간 프로세스의 상태를 불러와야 합니다.
이 순간에 프로세스 상태를 교체하고 새로운 CPU 레지스터 변수들을 불러오는 작업을 컨텍스트 스위칭(Context Switching)이라고 합니다.
점유에 벗어나는 순간에 프로세스의 상태를 저장해야 합니다.

프로세스마다 각자 고유 상태를 갖고 있습니다. 이를 PCB(Process Control Block)이라고 합니다.
현재 프로세스 상태가 실행 중인지, 대기 중인지를 알려주는 Process State,
고유 프로세스의 식별값을 나타내는 Process ID,
다음 실행할 프로그램 코드 위치를 저장하는 Program Counter,
메모리 정보를 관리할 페이지 테이블과 세그먼트 테이블, CPU의 스케쥴링 큐 포인터와 우선순위 정보, I/O 정보들 등등으로 이루어져 있습니다.

반면, 스레드는 하나의 프로세스 안에서 실행되는 여러 코드 흐름을 뜻합니다.
프로세스가 갖고 있는 Text 영역, Data 영역, Heap 영역을 공유하지만, 스레드 내부에서 Stack을 별도로 할당받습니다. 어떤 프로그램이든 하나의 주요 흐름을 실행하는 Main 스레드는 가지고 있습니다.
Data 영역과 Heap 영역을 공유하기에 다른 스레드와 데이터를 통신할 수 있지만, 어느 스레드가 먼저 실행할 지 모르기에 동기화와 교착 상태에 각별한 주의가 필요합니다.

A : 프로그램 코드 실행을 하드웨어단에서 어떻게 하나요?
프로그램을 실행할 때, 적당한 메모리 위치에 프로그램이 쓸 영역을 올립니다.
프로그램이 사용할 영역은 방금 말씀드렸다시피 코드를 저장하는 영역, 전역 정적 변수들을 저장하는 영역, 지역 변수들을 저장하는 영역, 동적메모리 할당을 받을 영역으로 나누어져있습니다.

그 다음 코드를 해석하고 실행하는 장소는 CPU 입니다.
CPU 에서는 Program Counter 라는 레지스터 변수로 다음 실행할 위치의 코드를 저장하는데요.
PC 위치에 있는 코드를 메모리로부터 읽어오고 명령어를 해석하여 적절한 행동을 실행합니다.
다시 PC에 다음 코드의 위치를 저장하고 프로그램이 종료할 때 까지 반복합니다.

A : 프로그램을 메모리에 올릴 때, 적당한 메모리 공간의 위치를 어떻게 효율적으로 정할 수 있을까요?
메모리에 필요한 공간을 할당할 때, 메모리의 빈 공간을 탐색해서 할당합니다.
모든 프로그램마다 할당받을 메모리의 크기도 모두 다르기에, 무턱대고 할당하고 해제하기를 반복한다면
메모리의 빈 공간을 탐색하는데 시간이 많이 들 뿐 더러, 불필요하게 빈 메모리가 많이 생길 것 입니다.

효율적인 메모리 관리 기법으로 할당할 메모리 주소의 탐색 시간을 줄이고 빈 메모리 공간을 줄입니다.
이를 관리하는 하나의 하드웨어 단위가 있습니다. 바로 MMU (Memory Management Unit) 입니다.

최초의 메모리 할당 방법은 연속적으로 할당하는 방법입니다. MMU에서 Offset 레지스터로 CPU가 읽은 가상 주소로부터 물리 주소에 매핑을 시켜주는 역할을 합니다. 현재 프로그램 영역을 벗어나지 않도록 Limit 레지스터로 주소 접근을 제한하기도 합니다. 만약에 제한을 넘어갔을 때 인터럽트로 시스템에게 예외를 처리하도록 부탁합니다. 연속적 할당 방법의 장점은 구현이 간단합니다. 그러나 초반에 말했던 단점들은 고스란히 남아있습니다.
할당과 해제의 과정을 거치면서 메모리 중간에 빈 공간들이 생겨나는데요.

빈 공간들을 모조리 합치면 새로 들어올 프로그램의 메모리를 옮길 수 있지만,
연속적으로 할당한다는 특징으로 할당이 불가능합니다.
총 여유 메모리로 충분히 할당하고도 남지만, 실제로 할당할 수 없는 경우를 외부 단편화(External Fragmentation) 라고 합니다.
메모리 공간의 빈 공간들을 모두 없애 앞쪽으로 땡기는 Compact 기법이 있습니다. 하나 하나 메모리 영역을 복사하여 빈 공간이 없도록 반복하게 되는데, I/O 문제가 발생할 수 밖에 없습니다.

이를 해결할 방법은 메모리 영역을 쪼개는 방식입니다. 이를 페이징(Paging) 방식이라고 합니다.
할당 받은 프로그램의 물리 메모리를 특정 크기의 프레임으로 쪼개 순서에 상관없이 저장합니다.
그렇다면, 각 프로세스는 어떻게 순서대로 프로그램을 실행할 수 있을까요?
프로세스 별로 페이지 테이블을 가지고 있습니다. 논리적인 페이징 테이블로 해당하는 실제 메모리 주소에 있는 프레임을 매핑하여 위치를 찾아냅니다.

페이징 방식의 장점으로 프로그램 메모리를 잘개 쪼개 효율적으로 메모리에 저장하여 외부 단편화를 해소한다는 점이고요. 페이징 방식의 단점으로는 특정 크기의 프레임으로 메모리 영역을 분리하는데요.
만약에 메모리 크기가 딱 맞지 않다면은 여전히 빈 공간이 생깁니다.
이를 내부 단편화(Internal Fragmentation)라고 합니다.
프레임 크기를 줄일수록 페이지 테이블이 커지고 그에 따른 오버헤드는 훨씬 빈번히 발생할 것 입니다.

물리 메모리에 접근할 때 늘 페이지 테이블에 접근해서 매핑된 물리 메모리에, 총 두 번 접근합니다.
이를 개선하기 위해 연관 메모리인 TLB(Translation Look-aside Buffer, 변환 색인 버퍼)를 사용합니다.
페이지 테이블을 대상으로 일종의 캐시 역할을 해줍니다.

더 나아가 메모리 크기가 커지면서 페이지 테이블을 여러 단계로 계층화 시킨다든지, 해쉬 테이블을 이용한다든지, 하나의 페이지 테이블로 통합시킨다든지 하는 방법들이 나왔습니다.
자세히는 모르지만 현대에 와서는 멀티 코어 시대인만큼 병렬화를 적극 이용하지 않았을까 싶습니다.

A : 프로그램 코드를 읽어올 때 CPU에서 어떻게 효과적으로 읽을 수 있는지 생각해보셨나요?
CPU와 메모리의 연산 속도는 다르기에 CPU 에서도 효과적으로 메모리로부터 데이터를 읽는 방법이 필요합니다. CPU 내부에 여러 캐시 메모리를 장착하고 있어 최대한 CPU 사이클보다 느린 메모리로부터 데이터나 코드를 불러오는 것을 지양하면서 캐시 메모리를 적극 활용해 속도를 개선합니다.

코드를 읽을 때, 메모리에서 다음에 실행할 코드 뭉치들을 미리 불러와 캐시 메모리에 저장합니다.
캐시 메모리에 저장한 명렁어들을 소진될 때 까지 순차적으로 실행해 속도를 개선합니다.

B : Context Switching이 일어날 때 운영체제 내에서 어떻게 동작하나요?
현재 프로그램 코드에서 다른 프로그램 코드 영역으로 옮길 때, 현재 프로세스의 레지스터 정보와 PCB를 저장합니다. 운영체제 내에서 레지스터 정보와 PCB를 저장하는 테이블에 등록합니다. 그리고 다른 프로세스의 정보를 탐색해 불러옵니다. 다시 원래 프로세스로 돌아올 때 저장했던 테이블에서 탐색해 불러옵니다.

C : 스레드 동기화는 어떻게 이루어지나요?
스레드 간에 객체를 공유하여 수정할 시, 다른 스레드에도 그 정보가 반영되지 않아 예상치 못한 오류가 일어날 수 있습니다.

멀티 스레드 환경에서 단 하나의 스레드만 실행할 수 있는 코드 영역을 임계 영역이라고 합니다.

자바에서는 이를 위해 동기화(synchronized) 메소드와 동기화 블록을 제공합니다.

스레드 내부의 동기화 메소드 또는 블록에 들어가면 즉시 객체에 잠금을 걸어 다른 스레드가 해당 임계 영역 코드를 실행하지 못하도록 합니다.



C : 자바에서 스레드의 상태를 제어하는 방법을 알려주세요.
스레드는 다음과 같은 상태를 가집니다, NEW, RUNNABLE, TIMED_WAITING, BLOCKED, TERMINATED.
스레드 객체를 생성하고 start() 메소드가 호출되지 않은 상태일 때 NEW 상태입니다.
RUNNABLE 은 실행 상태로 언제든지 갈 수 있는 상태입니다.
WAITING은 다른 스레드가 notify 해줄 때 까지 기다리는 상태입니다.
TIMED_WAITING은 주어진 시간 동안 기다리는 상태입니다.
BLOCKED는 사용하고자 하는 객체의 락이 풀릴 때 까지 기다리는 상태입니다.
TERMINATED는 실행을 마친 상태입니다.

스레드의 wait() 메소드는 동기화 블록 내에서 스레드를 WAITING 상태로 만듭니다. 매개값으로 주어진 시간이 지나면 자동적으로 RUNNABLE 상태가 된다. 주어지지 않으면, notify(), notifyAll() 메소드로 RUNNABLE 상태로 이동한다.

notify(), notifyAll() 메소드는 동기화 블록 내에서 wait() 메소드에 의해 WAITING 상태에 있는 스레드들을 RUNNABLE 상태로 만든다.

join() 메소드를 호출한 스레드는 WAITING 상태로 만든다. RUNNABLE 상태로 가기 위해서 join() 메소드를 호출 받은 스레드가 종료되거나, 매개값으로 주어진 시간이 지나야 한다.

forest.grass : 멀티 스레드 환경이면 무조건 동기화를 사용해야 하나요?
공유 객체를 사용할 일이 없다면, 동기화 메소드와 동기화 블록을 사용할 이유가 없지 않을까 싶습니다.

공유 객체란, 외부에서 들어오는 레퍼런스 타입의 객체 라든지, 전역으로 관리되는 객체 등의 외부에서도 접근 가능한 객체를 뜻합니다.

forest.grass : 스프링 프레임워크에서 여러 스레드가 컨트롤러라는 공유 객체를 쓸 텐데, 이는 스레드에 안전한가요?
기본적으로 스프링 빈에서 객체를 생성할 때 싱글톤으로 만들고 Application Context 에 저장합니다.
서블릿은 대부분 멀티 스레딩 환경에서 싱글톤을 동작하고 서블릿 클래스 하나 당 하나의 객체를 생성해, 클라이언트 요청 처리를 맡은 스레드들이 공유해서 사용합니다.

스프링 빈에서 Thread - safe 를 보장하려면 무상태성(Stateless)을 지켜야 합니다.
상태 정보를 클래스 내부에 가지고 있으면 안됩니다. 다른 싱글톤 빈을 저장하는 용도면은 사용 가능하다.
만약 객체 필드에 다른 스레드가 값을 변경할 여지가 있는 객체가 있다면, Thread-safe 하지 않으므로 공유 불가능한 스택 영역으로 옮기는 등의 조치를 취해야 합니다.

K.JY : 스레드 개수가 많아지면 더 효율적일까요?
아닙니다. 과도한 스레드 개수로 애플리케이션의 성능이 저하될 수 있습니다.

스레드 개수가 증가할수록, 스레드 생성과 스케줄링으로 CPU 점유율이 올라가고 메모리 사용량이 늘어납니다.



스레드의 폭증을 막으려면 스레드풀(ThreadPool)을 사용해야 합니다.

스레드를 제한된 개수만큼 정해 놓고 작업 큐에 들어오는 작업들을 하나씩 스레드가 맡아 처리합니다.

작업 처리가 끝난 스레드는 다시 작업 큐에서 새로운 작업을 가져와 처리합니다.



자바에서는 java.util.concurrent 패키지에서 ExecutorService 인터페이스와 Executors 클래스를 제공합니다.

Executors 클래스의 정적 메소드로 다양한 ExecutorService 구현 객체인 스레드풀을 만들 수 있습니다.



스레드풀의 종류는 세 가지가 있습니다.

newCachedThreadPool()은 동적 크기로 처리할 작업이 있을 때 새 스레드를 생성합니다. 60초 동안 추가된 스레드가 아무 작업을 하지 않으면 추가된 스레드를 종료하고 풀에서 제거합니다.

newFixedThreadPool()은 최대 스레드 개수를 설정하며, 유후 스레드가 있더라도 스레드 개수가 줄지 않습니다.

newSingleThreadPool()은 하나의 스레드를 생성하며, 작업이 차례대로 실행되며 스레드 안전하다.

