- 동기, 비동기, Blocking, Non-Blocking
    - 동기
        - I/O가 진행되는 동안 다음 명령을 수행하지 않고 기다린다.
          I/O 상태의 프로세스는 blocked state로 전환된다.
          I/O가 완료되면 인터럽트를 통해 완료를 알린다. 이후 CPU의 제어권이 기존 프로그램에게 넘어간다.
          blocked state의 프로세스는 wait 상태로 돌아간다.

        - 여러 프로세스가 동시에 I/O 요청을 할 경우 각 요청을 큐에 넣어 순서대로 처리한다.

    - 비동기
        - CPU의 제어권을 입출력 연산을 호출한 프로그램에게 곧바로 다시 부여
        - CPU는 I/O 결과와 상관 없이 처리 가능한 작업부터 처리한다.
        - I/O 연산이 완료되면 인터럽트를 통해 알린다.

    - Blocking I/O
        - 직접 제어할 수 없는 대상의 작업(I/O)이 완료될 때까지 기다린다.
            - I/O가 완료되어야 제어권이 프로세스로 넘어간다.
        - 동기와 마찬가지로 자원이 낭비된다.

    - Non-Blocking I/O
        - 외부에 I/O 작업을 하도록 요청한 후, 즉시 다음 작업을 처리
            - 시스템 자원을 더 효율적으로 사용할 수 있게된다.
        - I/O 작업이 완료된 이후에 처리해야 하는 후속 작업이 있다면, I/O 작업이 완료될 때까지 기다려야 한다.
          따라서 이 후속 작업이 프로세스를 멈추지 않도록 만들기 위해 I/O 작업이 완료된 이후 후속 작업이 이어서 진행할 수 있도록 별도의 약속(Polling, Callback function 등)을 한다.

    - 동기/비동기는 인터럽트 발생으로 인한 제어권 반환 시점에 중점을 두고 Blocking/Non-Blocking은 제어권 자체에 중점을 둔다는 점에서 차이가 있다.


- Blocking I/O, Non-Blocking I/O(NIO)와 대용량 트레픽
    https://junghyungil.tistory.com/131
    https://m.blog.naver.com/PostView.nhn?blogId=joebak&logNo=220063974083&proxyReferer=https:%2F%2Fwww.google.com%2F
    https://helloinyong.tistory.com/293
    - Thread 수는 접속자 수가 많아질 수록 Thread 수도 많아지게 된다. Thread 가 많으면 CPU 의 Context Switching 및 interrupt 횟수와 오버헤드 증가하게 된다.
      이러한 것들이 발생할 때 cpu 는 일하지 못한다. 때문에, 실제 작업하는 양에 비하여 훨씬 비효율적으로 동작하게 될 것이다. 즉, 성능에 악영향을 줄 수 있다.
      그래서 NIO 는 Non-Blocking 방식으로 이 문제를 해결하였다

    - Non-Blocking I/O은 I/O 작업을 진행하는 동안 쓰레드의 작업을 중단시키지 않는다. 쓰레드가 커널에게 I/O를 요청하는 함수를 호출하면,
      함수는 I/O를 요청한 다음 진행상황과 상관없이 바로 결과를 반환한다.
      I/O는 스트림으로 단 반향으로만 가능하지만, NIO 는 Channels 과 Buffers 를 이용해 양방향으로 가능하다. 또 Selectors 가 있다.

    - Channels
        - 채널은 항상 데이터를 버퍼로 읽고 버퍼는 데이터를 채널에 쓴다.
            채널을 읽고 쓸 수 있다. 스트림은 일반적으로 단방향 (읽기 또는 쓰기)이다.
            채널은 비동기 적으로 읽고 쓸 수 있다. ( ServerSocketChannel 이나 SocketChannel 의 경우는 Selector 를 활용해 Non-Blocking 프로그래밍이 가능하다.)
            채널은 항상 버퍼에서 읽거나 버퍼에서 쓴다.
            채널에서 버퍼로 데이터를 읽고 버퍼에서 채널로 데이터를 쓴다.

    - Buffers
        - Java NIO 버퍼는 NIO 채널과 상호 작용할 때 사용된다. 버퍼는 기본적으로 데이터를 쓸 수있는 메모리 블록이며 나중에 다시 읽을 수 있다.
          이 메모리 블록은 NIO Buffer 객체로 래핑되어 메모리 블록으로 작업하기 쉽게하는 일련의 메서드를 제공한다.

    - Channels 과 Buffers 를 이용한 Non-Blocking I/O - NIO
        - 자바 NIO 에서는 non-blocking IO를 사용할 수 있다.
        - 하나의 스레드는 버퍼에 데이터를 읽도록 채널에 요청할 수 있다.
          채널이 버퍼로 데이터를 읽는 동안 스레드는 다른 작업을 수행할 수 있다.
          데이터가 채널에서 버퍼로 읽어지면, 스레드는 해당 버퍼를 이용한 processing(처리)를 계속 할 수 있다.
          데이터를 채널에 쓰는 경우도 non-blocking 이 가능하다.

    - Selectors
        - 셀렉터를 사용하면 하나의 스레드가 여러 채널을 처리(handle)할 수 있다.
        - 셀렉터는 사용을 위해 하나 이상의 채널을 셀렉터에 등록하고 select() 메서드를 호출해 등록 된 채널 중 이벤트 준비가 완료된 하나 이상의 채널이 생길 때까지 봉쇄(block)된다.
        - 메서드가 반환(return)되면 스레드는 채널에 준비 완료된 이벤트를 처리할 수 있다.
          즉, 하나의 스레드에서 여러 채널을 관리할 수 있으므로 여러 네트워크 연결을 관리할 수 있다. (SocketChannel, ServerSocketChannel)

    - 커널 수준의 쓰레드 vs  사용자 수준의 쓰레드
        - 커널 수준의 쓰레드
            - 커널 수준 스레드는 커널 레벨에서 생성되는 스레드이다. 운영체제 시스템 내에서 생성되어 동작하는 스레드로, 커널이 직접 관리한다.
            - 그런데 커널 수준에서는 프로세스가 주기억 장치에 여러 개가 적재되어 CPU 할당을 기다리며 동작한다.
            - CPU 에서 인터럽트 발생으로 현재 작업 중인 프로세스가 Block 되고 다른 프로세스로 변경할 때,
              CPU 내 재배치 레지스터에 다음에 실행할 프로세스 정보들로 교체를 하고 캐시를 비운다. 이것을 컨텍스트 스위칭이라고 한다.
            - 이 컨텍스트 스위칭이 일어날 때는 CPU 가 일을 못한다. 그래서 이게 자주 일어나면 성능에 영향이 발생하게 되는 단점이 있다.
            - 하지만 커널이 직접 관리하므로 특정 스레드가 Block 이 되어도 다른 스레드들은 독립적으로 일을 할 수 있다.

        - 사용자 수준의 쓰레드
            - 스레드를 관리하는 라이브러리로 인해 사용자 단에서 생성 및 관리되는 스레드
            - 커널이 따로 관리하지 않고, 커널이 이 스레드에 대해서 알지도 못한다. (한 마디로 커널 레벨 밖에 있는 스레드)
            - 여기의 스레드는 운영체제 단의 기능을 하는 것이 아니라, 개발자가 기능 구현할 때 현재 기능 내에서 일 처리를 하는 스레드를 만들 듯이,
              프로세스 내 커널과 관련 없는 기능들만 수행하는 스레드이다. 그래서 커널이랑 관련도 없고 커널은 이런 스레드들이 있는지도 모른다.
            - 그렇기에 사용자 수준 스레드는 컨텍스트 스위칭이 없는 것이고, 스레드 교체 등으로 인한 오버헤드 발생이 없는 것이다.
            - 쓰레드 패키지를 사용자 영역에 두고 운영체제 커널은 단일 프로세스만을 관리한다.
            - 쓰레드 패키지를 런타임 시스템에서 사용한다.
            - 운영체제를 사용하는 입장에서는 런타임 시스템도 하나의 프로세스로 인식한다.
            - 쓰레드를 운영하지 않는 운영체제제에서 실행할 수 있으므로 이식성이 뛰어나다.
            - 즉, 입출력 인터럽트가 발생하면 커널은 '사용자 모드'가 되어서 사용자 수준 스레드의 응답을 기다린다. 사용자 수준 스레드의 응답이 오면 다시 '커널 모드'로 변환되어 이어서 커널 스레드가 일 처리를 하게 되는 것이다.
            - 컨텍스트 스위칭이 발생하지 않는다.

            - 프로세스 내에서 스레드들끼리는 자원을 공유하여 일 처리를 하기 때문에(스레드 통신 기법), 커널이 관리하는 스레드는 스레드 동기화 기법으로 자원 관리를 할 수 있으므로,
              하나의 스레드가 Bloc 이 되어도 다른 스레드들은 커널 관리로 인해 계속해서 동기화가 되어 일 처리가 가능하다.
              하지만 사용자 수준 스레드는 커널의 관리를 받지 않음으로, Block 으로 인해 공유 자원의 무결성에 대한 문제가 발생할 수 있으므로
              하나의 스레드가 인터럽트 당하면 모든 스레드가 멈추도록 하는 것 아닐까 추측한다.

        -> Blocking I/O가 커널 수준의 쓰레드, Non-Blocking NIO 가 사용자 수준의 쓰레드

    -> 정리
        - Blocking I/O는 하나의 호출마다 Thread 를 생성한다. 그에 따른 컨텍스트 스위칭이 발생하기 때문에 성능상 단점이 있다.
        - Non-Blocking IO는 요청을 받는 Thread 는 오직 하나다. Thread 내부에서 채널과 버퍼를 이용하여 Non-Blocking 방식으로 진행한다. 그래서 컨텍스트 스위칭이 발생하지 않는다.
          Context-switching 은 OS 단에서 처리하는데 이것을 사용자(개발자)가 직접 처리한다는 개념에서 최적화 시킬 수 있다는 장점이 있다.
          직접 처리한다는 것은 단일 쓰레드의 내부로 NIO 의 채널과 버퍼를 이용해서
        - 하지만 요청이 적다면, Blocking I/O가 더 좋다. 호출마다 thread 를 생성하니 요청이 적은 서비스에는 최적의 성능을 낼 수 있다.
          cpu 코어 갯수많큼 쓰레드를 생성하는게 최적이다. (병렬 작업의 장점)
        - I/O의 요청이 많아질 때 생기는 성능상의 이유로, 많은 요청을 해결하기 위해 자바 1.4에서 NIO 가 나왔고, NIO 는 대용량 트레픽 처리를 위해 꼭 알아야 하는 개념


- Blocking IO와 Non-Blocking IO 의 차이를 말씀해주세요.
    https://junghyungil.tistory.com/131
    https://velog.io/@octo__/BlockingNon-Blocking-IO-IO-%EC%9D%B4%EB%B2%A4%ED%8A%B8-%ED%86%B5%EC%A7%80-%EB%AA%A8%EB%8D%B8
    https://luv-n-interest.tistory.com/1121

    - 동기
        - I/O 작업은 user space 에서 직접 수행할 수 없기 때문에 user process 가 kernel 에 I/O 작업을 요청하고 응답을 받는 구조.
          응답을 어떤 순서로 받는지 (synchronous, asynchronous)
          어떤 타이밍에 받는지 (blocking, non-blocking)
          에 따라 여러 모델로 분류되는 것이다.

        - 동기 작업이란 한 번에 하나씩 수행되는 것을 의미한다. 즉, 해당 작업이 끝나기 전까지는 현재 진행중인 작업 외의 다른 작업을 수행하지 못함.
          HTTP 요청은 요청을 하면 무조건 응답을 받는다. 이것이 동기적이라고 말할 수 있다.

        - 모든 I/O 요청-응답 작업이 일련의 순서를 따르는 것이다. 즉, 작업의 순서가 보장된다.
          작업 완료를 user space 에서 판단하고 다음 작업을 언제 요청할지 결정한다. 일련의 Pipeline 을 준수하는 구조에서 효율적이다.
          작업의 순서를 보장한다는 말은 '현재 작업의 응답'을 받는 시점과 '다음 작업을 요청'하는 시점을 맞추는 일이다.
          다음 작업이 있다는 것 자체가 순서가 있다는 것을 의미하며 결국 이전 작업이 완료되기 전까지 다음 작업이 수행되지 않는 것이다.

    - 비동기
        - 비동기 작업이란 한 번에 하나 이상이 수행될 수 있음을 의미. 즉, 형재 작업을 진행중이더라도 다른 작업을 수행할 수 있다.
          또한 작업에 대한 결과를 바로 원하지 않는다.
          ex) 내가 이메일을 보내는 작업은 상대방이 바로 답장하기를 원해서 보내는 작업은 아니다.

        - kernel 에 I/O 작업을 요청해두고 다른 작업 처리가 가능하나, 작업의 순서는 보장되지 않는다.
          작업 완료를 kernel space 에서 통보해준다.
          각 작업들이 독립적이거나, 작업 별 지연이 큰 경우 효율적이다.

        - 만약 다중 요청에 대한 처리와 동시성 처리를 잘할 수 있다면 비동기 작업의 속도가 더 빠를 것이다.
          하지만 서로 의존성이 있는 곳에서 작업을 한다면 비동기는 오히려 오류를 불러올 가능성이 높다.
          때문에 비동기 프로그래밍을 할 때는 서로 독릭접인 일에 대해서 수행하는 것이 좋다.

    - 블로킹
        - Thread 가 Blocking 이 된다는 것은 CPU 가 점유되어 실행되지 못함을 의미.
          요청한 작업이 모두 완료될 때까지 기다렸다가 완료될 때 응답과 결과를 반환 (대기 O)
          CPU 를 점유한다고 사용한다는 것은 아니다.

    - 논블로킹
        - System call 을 받았을 때 제어권을 바로 자신을 호출한 쪽으로 넘기며 자신을 호출한 쪽에서 다른 작업을 할 수 있도록 하는 것을 의미.
          자신은 작업을 그대로 이어 나간다.
          Thread 가 Waiting 하지 않으므로 CPU 제어는 그대로다.

        - 작업 요청 이후 결과는 나중에 필요할 때 전달받는다. (대기 X)
          요청한 작업 결과를 기다리지 않는다. (CPU 점유 X)
          중간중간 필요하면 상태 확인은 해볼 수 있다. (polling)

    * 동기 쓰레드는 작업을 끝내야 다른 작업을 진행할 수 있다. (블로킹과 비슷하지만 Waiting Queue 에 들어가지 않아도 된다.)
      블로킹 쓰레드는 Waiting Queue 에 들어가게 된다.
      논블로킹 쓰레드는 작업이 끝나든 말든 다른 작업을 이어서 한다. (Waiting Queue 에 들어가지 않는다.)
      비동기 쓰레드가 작업 중이면 다른 쓰레드에서 작업을 하는 것이다.

      쓰레드가 블로킹으로 작업을 수행한다면 해당 쓰레드는 Waiting Queue 로 들어가고 Waiting Time 동안 해당 쓰레드를 비동기적으로 수행시킬 수 있다.
      쓰레드가 논블로킹으로 작업을 수행한다면 쓰레드가 CPU 를 계속 점유한 채로 수행된다.
      동기/비동기는 위에서 해당 쓰레드가 하는 일에 대해서 Sequential 하게 수행할 것인가 아니면 Simultaneous 하게 할 것인가

    * 왜 블로킹을 하고 안하고 정해야할까?
        - 블로킹을 하는 이유는 해당 작업이 끝나지 않은 채로 다른 작업을 진행한다고 하자.
          뒤따라온 작업이 앞선 작업의 결과에 의존적인 작업이라면 예상치 못한 결과가 나올 수 있다.


    - Blocking IO 가 일어나면 스레드에는 무슨 일이 생길까요?
        - I/O 작업이 blocking 방식으로 구현되면 하나의 클라이언트가 I/O 작업을 진행하면 해당 쓰레드가 진행하는 작업을 중지하게 된다.
          영향을 미치지 않게 하기 위해서 클라이언트 별로 Thread 를 만들어 연결시켜주어야 한다. Thread 가 많아지면 시간 할당량은 작아진다.
          시간할당량이 작으면 동시에 수행되는 느낌을 가질 수 있다.
        - Thread 수는 접속자 수가 많아질 수록 Thread 수도 많아지게 된다. Thread 가 많으면 CPU 의 Context Switching 및
          interrupt 횟수와 오버헤드 증가하게 된다. 이러한 것들이 발생할 때 cpu 는 일하지 못한다. 때문에, 실제 작업하는 양에 비하여 훨씬
          비효율적으로 동작하게 될 것이다. 즉, 성능에 악영향을 줄 수 있다.
        - Non-Blocking 방식으로 이 문제를 해결
        - Non-Blocking I/O은 I/O 작업을 진행하는 동안 쓰레드의 작업을 중단시키지 않는다. 쓰레드가 커널에게 I/O를 요청하는 함수를 호출하면,
          함수는 I/O를 요청한 다음 진행상황과 상관없이 바로 결과를 반환한다.
        - I/O는 스트림으로 단 반향으로만 가능하지만, NIO 는 Channels 과 Buffers 를 이용해 양방향으로 가능하다. 또 Selectors 가 있다.
            - Channels
                - 일반적인 NIO 의 I/O는 채널에서 시작된다. Java NIO 채널은 몇 가지 차이점을 제외하고 스트림과 유사하다.
                - 채널은 항상 데이터를 버퍼로 읽고 버퍼는 데이터를 채널에 쓴다.
                - 채널을 읽고 쓸 수 있다. 스트림은 일반적으로 단방향 (읽기 또는 쓰기)이다.
                - 채널은 비동기 적으로 읽고 쓸 수 있다. ( ServerSocketChannel 이나 SocketChannel 의 경우는 Selector 를 활용해 Non-Blocking 프로그래밍이 가능하다.)
            - Buffers
                - Java NIO 버퍼는 NIO 채널과 상호 작용할 때 사용된다. 버퍼는 기본적으로 데이터를 쓸 수있는 메모리 블록이며
                  나중에 다시 읽을 수 있다. 이 메모리 블록은 NIO Buffer 객체로 래핑되어 메모리 블록으로 작업하기 쉽게하는 일련의 메서드를 제공한다.
            - Channels 과 Buffers 를 이용한 Non-Blocking I/O - NIO
                - 자바 NIO 에서는 non-blocking IO를 사용할 수 있다. 예를 들면,
                  하나의 스레드는 버퍼에 데이터를 읽도록 채널에 요청할 수 있다.
                  채널이 버퍼로 데이터를 읽는 동안 스레드는 다른 작업을 수행할 수 있다.
                  데이터가 채널에서 버퍼로 읽어지면, 스레드는 해당 버퍼를 이용한 processing(처리)를 계속 할 수 있다.
                  데이터를 채널에 쓰는 경우도 non-blocking 이 가능하다.
            - Selectors
                - 셀렉터를 사용하면 하나의 스레드가 여러 채널을 처리(handle)할 수 있다.
                - 셀렉터는 사용을 위해 하나 이상의 채널을 셀렉터에 등록하고 select() 메서드를 호출해 등록 된 채널 중 이벤트 준비가 완료된 하나 이상의 채널이 생길 때까지 봉쇄(block)된다.
                - 메서드가 반환(return)되면 스레드는 채널에 준비 완료된 이벤트를 처리할 수 있다.
                  즉, 하나의 스레드에서 여러 채널을 관리할 수 있으므로 여러 네트워크 연결을 관리할 수 있다. (SocketChannel, ServerSocketChannel)
        - 커널 수준의 쓰레드 vs 사용자 수준의 쓰레드
            - 커널 수준의 쓰레드
                - 커널 수준 스레드는 커널 레벨에서 생성되는 스레드이다.
                - 운영체제 시스템 내에서 생성되어 동작하는 스레드로, 커널이 직접 관리한다.
                - 그런데 커널 수준에서는 프로세스가 주기억 장치에 여러 개가 적재되어 CPU 할당을 기다리며 동작한다.
                - CPU 에서 인터럽트 발생으로 현재 작업 중인 프로세스가 Block 되고 다른 프로세스로 변경할 때,
                  CPU 내 재배치 레지스터에 다음에 실행할 프로세스 정보들로 교체를 하고 캐시를 비운다. 이것을 컨텍스트 스위칭이라고 한다.
                - 이 컨텍스트 스위칭이 일어날 때는 CPU 가 일을 못한다. 그래서 이게 자주 일어나면 성능에 영향이 발생하게 되는 단점이 있다.
                - 하지만 커널이 직접 관리하므로 특정 스레드가 Block 이 되어도 다른 스레드들은 독립적으로 일을 할 수 있다.
            - 사용자 수준의 쓰레드
                - 쓰레드 패키지를 사용자 영역에 두고 운영체제 커널은 단일 프로세스만을 관리한다.
                - 쓰레드 패키지를 런타임 시스템에서 사용한다.
                - 운영체제를 사용하는 입장에서는 런타임 시스템도 하나의 프로세스로 인식한다.
                - 쓰레드를 운영하지 않는 운영체제제에서 실행할 수 있으므로 이식성이 뛰어나다.
                - 즉, 입출력 인터럽트가 발생하면 커널은 '사용자 모드'가 되어서 사용자 수준 스레드의 응답을 기다린다.
                  사용자 수준 스레드의 응답이 오면 다시 '커널 모드'로 변환되어 이어서 커널 스레드가 일 처리를 하게 되는 것이다.
                - 컨텍스트 스위칭이 발생하지 않는다.
            -> Blocking I/O가 커널 수준의 쓰레드, Non-Blocking NIO 가 사용자 수준의 쓰레드라고 보면 될 것 같다.
        - 정리
            - Blocking I/O는 하나의 호출마다 Thread 를 생성한다. 그에 따른 컨텍스트 스위칭이 발생하기 때문에 성능상 단점이 있다.
            - Non-Blocking IO는 요청을 받는 Thread 는 오직 하나다. Thread 내부에서 채널과 버퍼를 이용하여 Non-Blocking 방식으로 진행한다.
              그래서 컨텍스트 스위칭이 발생하지 않는다.
            - 위에서 말한 사용자 수준 스레드 관점에서 봤을 때, Context-switching 은 OS 단에서 처리하는데 이것을 사용자(개발자)가
              직접 처리한다는 개념에서 최적화 시킬 수 있다는 장점이 있다. 직접 처리한다는 것은 단일 쓰레드의 내부로 NIO 의 채널과 버퍼를 이용해서
            - 하지만 요청이 적다면, Blocking I/O가 더 좋다. 호출마다 thread 를 생성하니 요청이 적은 서비스에는 최적의 성능을 낼 수 있다.
              cpu 코어 갯수많큼 쓰레드를 생성하는게 최적이다. (병렬 작업의 장점)
            - I/O의 요청이 많아질 때 생기는 성능상의 이유로, 많은 요청을 해결하기 위해 자바 1.4에서 NIO 가 나왔고,
              NIO 는 대용량 트레픽 처리를 위해 꼭 알아야 하는 개념

        - NIO  https://deftkang.tistory.com/24
            일반적으로 네트워크의 속도는 컴퓨터의 CPU, 메모리, 심지어 디스크의 속도와 비교해도 매우 느리다. 이러한 상황에서 나오는 현상중
            상대적으로 느린 네트워크를 엄청나게 빠른 CPU 가 기다리는 것이다. CPU 가 느린 네트워크를 기다리지 않고 네트워크보다 앞서
            달리게 하기 위한 전통적인 자바의 해결 방안은 버퍼링과 멀티스레드를 결합하는 것이다. 다수의 스레드가 동시에 다수의
            서로 다른 연결을 통해 보낼 데이터를 생성한다. 그리고 네트워크가 데이터를 보낼 준비가 될 때까지 해당 데이터들을 버퍼에 저장해 둔다.
            그러나 멀티 스레드를 생성할 때 드는 오버헤드와 스레드 전환 시 발생하는 오버헤드를 무시할 수 없다. 그리고 각각의 스레드는
            약 1메가 바이트의 메모리리를 여분으로 필요로 한다. 초당 수천 개의 요청을 처리하는 대규모 서버 환경에서는 스레드가 사용하는
            여분의 메모리와 다양한 오버헤드로 인해 연결마다 스레드를 할당하는 것이 쉽지 않다. 그래서 하나의 스레드가 다수의 연결을 담당하고,
            데이터를 수신할 준비가 된 연결을 골라내서 처리하고, 그리고 다시 준비된 다음 연결을 골라내는 방법을 반복한다면 훨씬 더 빠를 것이다.
            이러한 기능을 java.nio 패키지 에서 제공한다.
        - IO와 NIO 의 차이점
            - IO는 입력 스트림과 출력 스트림이 구분 되어 입/출력 별도의 생성이 필요하다.  또 동기(synchronous) 방식이기 때문에
              입력과 출력이 다 될때까지 스레드는 멈춰 있어야 한다. 이것을 블로킹이라고 하는데 interrupt 로 블로킹(Blocking)을
              빠져 나올 수 없다. 블로킹을 빠져 나오는 유일한 방법은 스트림을 닫는 것이다. 반면 NIO 는 양방향 입출력이 가능하므로
              하나만 생성하면 된다. 또 NIO 는 블로킹(Blocking)과 넌블로킹(Non-Blocking)을 지원하는데 넌블로킹 방식으로 입출력 작업시
              스레드가 블로킹 되지 않는다. 또 NIO 블로킹은 스레드 interrupt 로 인해 빠져 나오는 것이 가능하다.
            - IO
                - 스트림 방식
                - 넌버퍼
                - 동기 방식
                - 블로킹 방식
            - NIO
                - 채널 방식
                - 버퍼
                - 동기/비동기 방식 모두 지원
                - 블로킹/넌블로킹 방식 모두 지원
        - NIO 패키지 핵심개념
            1. 채널(Channel)
                - 채널은 파일, 소켓, 데이터그램 등과 같은 다양한 I/O 소스로부터 데이터 블록을 버퍼로 쓰거나 읽어 온다.
                - 비동기 읽기/쓰기를 지원하는 스트림과 같은 기술이다.
            2. 버퍼(Buffer)
                - nio(new input/output) 에서는 모든 I/O가 버퍼링된다. 게다가 버퍼는 새로운 I/O API의 기초를 이루고 있다.
                - 데이터를 입출력 스트림으로 쓰거나 읽지 않고 대신 버퍼에 일시적으로 저장하여 쓰고 읽는다.
                - 채널과 함께 동작한다.
            3. 셀렉터(Selector)
                - 싱글 스레드에서 다중채널을 처리 하기 위한 기술이다. 즉 준비된 채널을 선택함으로써 읽고 쓸 때 블록하지 않아도 된다.
                - 애플리케이션에서 싱글 스레드로 low-traffic 연결을 처리하는 경우 유용하다.

    - 스레드가 멈춰있는 동안 CPU 는 어떻게 될까요?
    - CPU 가 쉬는 것을 막으려면 어떻게 해야할까요?
    - 스레드를 늘리면 단점이 무엇일까요?
        - 이 것이 Tomcat 이 스레드를 수 백개씩 띄우는 이유입니다.
          Tomcat 은 일반적으로 Blocking 방식이기 때문에 스레드 1개당 요청 1개를 처리할 수 밖에 없습니다.
    - Non-Blocking IO는 CPU 활용률이 어떨까요?
        - Spring WebFlux 와 Netty
            - Spring WebFlux  https://alwayspr.tistory.com/44
                - I/O
                    - 사용자가 I/O 요청을 할 때 CPU 가 I/O Controller 에 요청을 하고 I/O Controller 가 파일을 다 가져오면 그것을
                      Memory 에 적재시키고 CPU 에게 완료되었다고 알려준다. 즉 큰 그림은 CPU -> I/O Controller -> CPU 의 형태이다.
                      핵심은 CPU 가 I/O를 직접 가져오는 것이 아니라, 작은 CPU 라고 불리는 I/O Controller 가 수행한다는 이야기이다.
                      좀 더 나아가면 작업을 단순히 위임시키고 작업이 완료되는 동안에는 다른 일을 수행할 수 있다는 말이다.
                      이러한 예처럼 I/O를 처리하는데 몇 가지 방법이 있다.
                - Blocking I/O
                    - Application 에서 I/O 요청을 한 후 완료되기 전까지는 Application 이 Block 이 되어 다른 작업을 수행할 수 없다.
                      이는 해당 자원이 효율적으로 사용되지 못하고 있음을 의미한다.
                    - 그러나 생각을 해보면 여러분들의 Application 들은 Blocking 방식임에도 불구하고 마치 Block 이 안된듯이
                      동작하는 것처럼 보인다. 이것은 여러분들이 Single Thread 를 기반으로 하는 것이 아닌 Multi Thread 를 기반으로
                      동작하기 때문이다. Block 되는 순간 다른 Thread 가 동작함으로써 Block 의 문제를 해소하였다.
                      그러나 Thread 간의 전환(Context Switching)에 드는 비용이 존재하므로 여러 개의 I/O를 처리하기 위해
                      여러 개의 Thread 를 사용하는 것은 비효율적으로 보인다.
                - Synchronous Non-Blocking I/O
                    - Application 에서 I/O를 요청 후 바로 return 되어 다른 작업을 수행하다가 특정 시간에 데이터가 준비가 다되었는지
                      상태를 확인한다. 데이터의 준비가 끝날 때까지 틈틈이 확인을 하다가 완료가 되었으면 종료된다.
                      여기서 주기적으로 체크하는 방식을 폴링(Polling) 이라고 한다. 그러나 이러한 방식은 작업이 완료되기 전까지
                      주기적으로 호출하기 때문에 불필요하게 자원을 사용하게 된다.
                - Asynchronous Non-blocking I/O
                    - I/O 요청을 한 후 Non-Blocking I/O와 마찬가지고 즉시 리턴된다. 허나, 데이터 준비가 완료되면 이벤트가 발생하여
                      알려주거나, 미리 등록해놓은 callback 을 통해서 이후 작업이 진행된다. 이전 두 I/O의 문제였던
                      Blocking 이나 Polling 이 없기 때문에 자원을 보다 더 효율적으로 사용할 수 있다.
                - Event-Driven
                    - Event-Driven 을 토대로 많은 프레임워크와 라이브러리가 발전하고 있다. 예) Spring WebFlux, Node.js, Vert.x 등
                    - Event-Driven Programming 은 프로그램 실행 흐름이 이벤트
                      (ex : 마우스 클릭, 키 누르기 또는 다른 프로그램의 메시지와 같은 사용자 작업)에 의해 결정되는 프로그래밍 패러다임이다.
                      Event 가 발생할 때 이를 감지하고 적합한 이벤트 핸들러를 사용하여 이벤트를 처리하도록 설계됐다. 순차적으로 진행되는
                      과거의 프로그래밍 방식과는 달리 유저에 의해 종잡을 수 없이 진행되는 GUI(Graphical User Interface)가
                      발전됨에 따라 Event-Driven 방식은 더욱더 많이 쓰이게 되었다.
                - Spring Framework
                    - Spring 은 Reactive Stack 과 Servlet Stack 두 가지 형태를 제공한다. 또한 Reactive Stack 은
                      non-blocking I/O를 이용해서 많은 양의 동시성 연결을 다룰 수 있다고 한다. 과거로 돌아가서 Servlet Stack 의
                      문제점을 파악하고 이를 어떻게 Reactive Stack 으로 해결했는지 알아보자.
                - Spring MVC
                    - 위 그림처럼 유저들로부터 HTTP 요청이 들어올 때 요청들은 Queue 를 통하게 된다. Thread pool 이
                      수용할 수 있는 수(thread pool size)의 요청까지만 동시적으로 작업이 처리되고 만약 넘게 된다면 큐에서 대기하게 된다.
                      즉 하나의 요청은 하나의 Thread 를 요구한다. (one request per thread model)
                    - Thread pool 은 다음과 같다. Thread 를 생성하는 비용이 크기 때문에 미리 생성하여 재사용함으로써 효율적으로 사용한다.
                      그렇다고 과도하게 많은 Thread 를 생성하는 것이 아니라 서버 성능에 맞게 Thread 의 최대 수치를 제한시킨다.
                      참고로 tomcat default thread size 는 200이다.
                    - 그런데 만약 대량의 트래픽이 들어와 thread pool size 를 지속적으로 초과하게 된다면 어떻게 될까?
                    - 설정해놓은 thread pool size 를 넘게 되면 위 그림처럼 작업이 처리될 때까지 Queue 에서 계속해서 기다려야 한다.
                      그래서 전체의 대기시간이 늘어난다. 이런 현상을 Thread pool hell 이라고 한다.
                    - Thread pool 이 감당할 수 있을 때까진 빠른 처리속도를 보이지만, 넘는 순간부터는 지연시간이 급격하게 늘어난다.
                    - 특수한 경우를 제외하면 DB, Network 등의 I/O가 일어나는 부분에서 아마 시간을 많이 소비했을 것이다.
                    - 설명했듯이 I/O 작업은 CPU 가 관여하지 않는다. I/O Controller 가 데이터를 읽어오고 이를 전달받을 뿐이다.
                      위에서 I/O를 처리하는 3가지 방식을 소개했는데 가장 효율이 좋은 방법은 마지막에 설명한
                      Asynchronous Non-blocking I/O 이라고 하였다. Blocking 방식은 I/O Controller 가 데이터를 읽는 동안 CPU 가
                      아무 일도 할 수가 없고, Non-Blocking 방식은 polling 때문에 불필요하게 CPU 를 소비한다고 했다.
                      Spring 에서도 Non-blocking I/O를 이용해서 효율적으로 작업을 처리할 수 있는 방법을 제공한다. 그 수단이 WebFlux 이다.
                - Spring WebFlux
                    - 사용자들에 의해 요청이 들어오면 Event Loop 를 통해서 작업이 처리가 된다. one request per thread model 과의
                      차이점은 다수의 요청을 적은 Thread 로도 커버할 수 있다. worker thread default size 는 서버의 core 개수로
                      설정이 되어있다. 즉 서버의 core 가 4개라면 worker thread 는 4개라는 말이며 이 적은 Thread 를 통해서도
                      traffic 을 감당할 수 있다. 위에서 하나의 Thread 로 3초가 걸리는 API 1000개를 호출했음에도 4초밖에 안 걸렸다는 걸
                      상기시키면 이해에 도움이 될 것이다. 또한 비슷한 Architecture 를 가진 Node.js가 이미 증명을 하고 있다.
                    - 이렇듯 Non Blocking 방식을 활용하면 좀 더 효율적으로 I/O를 제어할 수 있고 성능에도 좋은 영향을 미친다.
                      특히나 유행하는 MSA 에서는 수많은 Microservice 가 거미줄처럼 서로를 네트워크를 통해서 호출하고 있다.
                      즉 많은 수의 Network I/O가 발생할 텐데 이를 Non Blocking I/O를 통해 좀 더 성능을 끌어올릴 수 있다.
                    - 그러나 물론 제한된 점이 있다. WebFlux 로 성능을 최대치로 끌어올리려면 모든 I/O 작업이 Non Blocking 기반으로
                      동작해야 된다. Blocking 이 되는 곳이 있다면 안 하느니만 못한 상황이 되어버린다.
                      예를 들어 멀티코어로 가정을 해보자. 그럼 처리할 수 있는 Thread 는 2개인데 Blocking 이 걸리는 API 를 열명 이서
                      동시에 호출한다면 결국엔 Spring MVC 처럼 8명이 I/O 작업이 끝날 때까지 기다려야 하는 구조가 되어버리기 때문이다.

                    - Java 진영에는 아쉽게도 DB connection 을 non-blocking 으로 지원하는 라이브러리가 널리 보급되어 잘 사용되지는 않고 있다.
                      다만 R2DBC 처럼 개발이 진행 중인 라이브러리, 최근에 release 된 jasync sql 등이 있으며, MongoDB, Redis 등의 NoSQL 은 지원중이다.
                    - 또한 소수의 Thread 에 의해서 수많은 요청을 처리하고, 순서대로 작업이 처리되는 것이 아니라 Event 에 기반하여
                      실타래가 엉킨 것처럼 작업이 처리되기 때문에 트래킹 하기에 힘이 들다는 문제가 있다.

                    - 그렇다면 성능이 좋으니 무조건 WebFlux 를 사용해야 할까?
                        - 위 그림은 Spring MVC 나 Spring WebFlux 둘 다 성능이 동일한 구간이 있다. 서버의 성능이 좋으면 좋아질수록
                          해당 구간은 더 늘어날 것이다. 그렇기에 만약 여러분의 환경이 해당 구간이라면 굳이 사용할 필요가 없다.
                          또한 Spring Document 에서는 동기 방식이 코드 작성, 이해, 디버깅하기 더 쉽다고 한다. 이 말은 즉 높은 생산성을
                          가진다는 말과 같은 것으로 보인다. 그렇기에 이해타산을 잘 따져서 선택해야 할 필요가 있다.
                        - 그리고 우리는 이제 왜 성능이 동일한 구간이 생기는 지를 알 수 있다. 저 구간은 바로 Thread Pool 이
                          감당할 수 있을 정도의 요청이었기에 비동기적으로 잘 수행하다가 이후에는 Queue 에 쌓여 점점 성능이 느려졌던 것이다.
                        -> 'Spring WebFlux 는 어떻게 적은 리소스로 많은 트래픽을 감당할까?'란 궁금증을 시작으로 여기까지 왔다.
                           이에 대한 답은 I/O를 Non Blocking 을 이용하여 잘 사용하는 것과 Request 를 Event-Driven 을 통해서
                           효율적으로 처리하기 때문에 가능하다.

            - Spring MVC vs WebFlux   https://devmoony.tistory.com/174   https://woowabros.github.io/experience/2020/02/19/introduce-shop-display.html
                - WebFlux
                    - Spring WebFlux 는 Spring 5에서 새롭게 추가된 모듈
                    - 장점 : 고성능, spring 과 완벽한 통합, netty 지원, 비동기 non-blocking 메세지 처리
                      단점 : 오류처리가 다소 복잡하다.
                    - Spring WebFlux 는 아래와 같은 용도로 사용하기를 추천
                        - 비동기, 논블로킹 reactive 개발에 사용하는 경우
                        - 효율적으로 동작하는 고성능 웹어플리케이션 개발에 사용
                        - 서비스간 호출이 많은 마이크로서비스 아키텍처에 적합
                    - 논블로킹과 블로킹 코드를 같이 사용하게 되면 비동기 코드가 무의미해지고 성능적인 이점도 볼 수 없기 때문에 고려해야 할 부분이 많다.\

                - Spring MVC
                    - 1 request : 1 thread
                    - sync + blocking
                - WebFlux
                    - many request : 1 thread
                    - async + non-blocking

                -> Spring MVC 는 1:1로 요청을 처리하기 때문에 트래픽이 몰리면 많은 쓰레드가 생겨난다. 쓰레드가 전활될 때 컨텍스트 스위칭 비용이
                   발생하게 되는데 쓰레드가 많아질수록 비용이 커지기 때문에 적절한 쓰레드 수를 유지해야 하는 문제가 있다.
                   이에 반해 WebFlux 는 Event-Driven 과 Asynchronous Non-blocking I/O 를 통해 리소스를 효율적으로 사용할 수 있도록 만들어 준다.


- Blocking vs Non-Blocking, Sync vs Async
    - Blocking vs Non-Blocking
        - Blocking: 자신의 작업을 진행하다가 다른 주체의 작업이 시작되면 다른 작업이 끝날 때까지 기다렸다가 자신의 작업을 시작하는 것
        - Non-Blocking: 다른 주체의 작업에 관련없이 자신의 작업을 하는 것
        -> 다른 주체가 작업을 할 때 자신의 제어권이 있는지 없는지로 볼 수 있다.

    - Synchronous vs Asynchronous
        - Synchronous: 작업을 동시에 수행하거나, 동시에 끝나거나, 끝나는 동시에 시작함을 의미
        - Asynchronous: 시작, 종료가 일치하지 않으며, 끝나는 동시에 시작을 하지 않음을 의미
        -> 결과를 돌려주었을 때, 순서와 결과에 관심이 있는지 아닌지로 판단할 수 있다.

    - Blocking/Sync
        ex) 자바에서 입력요청을 할 때

    - Non-Blocking/Sync
        - Blocking/Sync 와 큰 차이가 없다.

    - Blocking/Async
        - 보통 Non-Blocking/Async 로 하려다가 개발자의 실수로 혹은 기타 이유로 이와 같이 동작

    - Non-Blocking/Async
        ex) 자바스크립트에서 API 요청을 하고 다른 작업을 하다가 콜백을 통해서 추가적인 작업을 처리할 때


- 멀티스레드와 동기화
    - 공유자원과 임계영역
        - 공유자원: 여러 스레드가 동시에 접근할 수 있는 자원
        - 임계영역: 공유자원들 중 여러 스레드가 동시에 접근했을 때 문제가 생길 수 있는 부분

    - 경쟁상태
        - 둘 이상의 스레드가 공유자원을 병행적으로 읽거나 쓰는 동작을 할 때 타이밍이나 접근 순서에 따라 실행 결과가 달라지는 상황
        - Read - Modify - Write, Check - then - act 라는 두 가지 패턴 존재
            - Read - Modify - Write
              경쟁 상태가 발생하는 연산의 패턴 중 가장 유명한 패턴
              메모리에 값을 읽어오고 수정하고 덮어쓰는 세 가지 연산으로 분리가 되는 것
            - Check - then - act
              if 분기문을 통과하기 전에는 조건에 부합했지만, if 분기문을 통과한 후에는 조건에 부합x

    - 원자성과 가시성
        - 원자성
            - 공유 자원에 대한 작업의 단위가 더이상 쪼갤 수 없는 하나의 연산인 것처럼 동작하는 것
            - Read - Modify - Write
                1. 메모리에서 값을 읽어옴 (read)
                2. 읽어온 값을 수정 (modify)
                3. 수정한 값을 다시 메모리에 덮어씀 (write)
                -> 1 2 번 사이에 시간 텀이 생기게 되므로 한 쓰레드가 연산을 할 때 다른 쓰레드의 연산이 개입할 수 있다.
                   이런 경쟁 상태를 발생시키지 않기 위해서는 분리된 명령어들을 하나로 모아주는 과정이 필요한데 이걸 원자성이라 한다.
            - Check - then - act
                1. 분기문 비교 (read)
                2. 로직 (act)
        - 가시성
            - 쓰레드를 실행하는 건 CPU 가 실행을 하는데 쓰레드를 CPU 가 실행할 때 메인 메모리에서 변수 값을 읽어와서 쓰레드를 실행.
              그런데 메인 메모리와 CPU 간의 거리가 멀어서 CPU 캐시 사용. CPU 는 이 쓰레드를 실행할 때 필요한 값을 메인 메모리에서 읽어와서
              CPU 캐시에 담아두고 CPU 캐시의 모든 연산을 반영한 다음 그 값을 메인 메모리에 덮어쓰는 방식으로 동작
            - 메인 메모리에 있는 진짜 값을 보지 못해서 가시성 이라고 함
            - volatile 변수를 선언하면 이 변수는 메인 메모리에서만 값을 읽고 쓰고 CPU 캐시를 사용하지 않는 변수가 된다.

    - 동기화
        - 블로킹
            - 특정 스레드가 작업을 수행하는 동안 다른 작업은 진행하지 않고 대기하는 방식
              ex) Monitor, Synchronized 키워드
            - 모니터
                - 자바에서 동기화를 하기 위한 도구
                - 배타동기큐는 synchronized, 조건동기큐는 wait(), notify(), notifyAll()
                - 임계영역에는 한번에 한 스레드만 락을 가지고 들어가도록 설계되어 있음.
                  만약에 임계영역에 접근하는 여러 스레드가 있다면 그 중에 한 스레드가 먼저 임계영역에 들어갈 수 있고 작업을 수행하다가
                  wait() 라는 연산을 만나면 이 스레드는 슬립 상태가 되면서 조건동기큐로 들어가게 된다. 배타동기큐에 있던 다른 스레드들이
                  임계영역이 비어있기 때문에 임계영역에 락을 가지고 들어올 수 있다. 다른 스레드가 임계영역에서 작업을 수행하다가
                  notify()나 notifyAll()이라는 메서드를 호출하게 되면 조건동기큐에서 자고 있던 스레드가 깨어나면서 임계영역이 비어 있을 때
                  다시 임계영역으로 돌아와서 작업을 수행하도록 하는 걸 모니터 메커니즘이라고 함.
            - Synchronized
                - 배타동기를 선언하는 키워드
                - 연산결과가 메모리에 써질때까지 다른 스레드는 임계영역에 들어오지 못하고 대기
                - 동작 방식
                    임계영역에 한 개의 스레드만 들어올 수 있기 때문에 이 스레드가 들어오고 나서 자기가 연산할 것을 다 연산하고 메인 메모리에
                    반영시킨 이후에 임계영역에서 나가게 된다. 그리고 나서 다른 스레드가 임계영역에 들어오게 되고 들어올 때는 메인 메모리에서
                    이미 동기화된 값을 읽어오기 때문에 문제가 발생하지 않음. 이렇게 순차적으로 접근하는 방식 때문에 원자성과 가시성을
                    모두 만족
                - 단점
                    - 하나의 쓰레드만 임계영역에서 작업을 수행할 수 있기 때문에 나머지 대기하는 스레드들이 발생하고 성능저하로 이어질 수 있음
                    - 임계영역에 들어갈 때 락을 획득하고 들어가기 때문에 데드락이 발생할 수 있다.
                        - 계속 자기가 잡고 있는 자원을 놓지 않고 상대방이 가지고 있는 자원을 놓기를 계속 기다리고 있는 상태가 데드락 상태

        - 논블로킹
            - 다른 스레드의 작업여부와 상관없이 자신의 작업을 수행하는 방식
              ex) Atomic 타입
            - CAS 알고리즘 (Compare and Set)
                - 연산을 할 때 자원 값을 가져오는 데 가져올 때 자원 값이랑 똑같은 값에 기대 값이라는 걸 만든다.
                  이 기대값을 기반으로 연산을 진행해서 새로운 값을 도출. 이 새로운 값을 자원 값에다 덮어쓰기 하기 직전에 내가 이전에
                  만들었던 기대값과 현재의 자원값이 같은지를 확인하는 로직이 있다. 같으면 기존 자원값을 새로운 값으로 수정하고 true, 다르면
                  수정하지 않고 false. 이렇게 자원값과 기대값을 비교하는 과정에서 CAS 를 통해서 원자성을 보장.
                - false 를 반환했을 때 이후에 동작은 어떻게 할 것인지는 개발자의 요구사항에 따라 달라짐.
                  while 문을 계속 돌면서 이 조건이 true 가 나올 때까지 계속 재시도 하는 방법이 있고 아니면 몇 번 시도하다가 exception 을
                  터뜨리고 끝내는 방법도 있다.
            - Atomic 타입
                - 동시성을 보장하기 위해서 자바에서 제공하는 래퍼 클래스
                - CAS 와 Volatile 을 활용해서 원자성과 가시성을 보장
                - AtomicReference
                    - 보통 일반적인 스레드에서는 값을 연산하고자 할 때 연산하는 값을 끌어올 때는 JVM 과 CPU 사이에 있는 캐시값에서 변수를
                      끌어옴. 근데 아토믹 레퍼런스를 설정하게 되면 내부에 volatile 이 박혀있어서 JVM 메모리에서 바로 스레드로 값을
                      당겨올 수 있다. 바로 값을 당겨와서 연산을 진행하게 되는데 연산을 할 때는 compareAndSet() 이라는 메소드가 호출된다.
                      CAS 알고리즘을 녹인 메소드인데 이걸 실행하면 현재 메모리에 저장된 값과 스레드 내부에 이미 만들어 놨던 기대값을
                      비교해서 일치하면 true, 아니면 false 를 반환하는 식으로 동작. 그래서 아토믹 레퍼런스가 volatile 을 통해서 가시성을
                      CAS 를 통해서 원자성을 보장.

    - 스레드 안전한 객체 설계 방법
        - 여러 스레드가 동시에 클래스를 사용하려 하는 상황에서 클래스 내부의 값을 안정적인 상태로 유지할 수 있는 것을 스레드 세이프.
        - 여러 방법들이 있는데 전략에 따라서 선택을 달리 해야하고 구현에 따라서 장단점도 다르다.
        - 가장 확실하고 안전하고 간단한 방법 -> 공유변수 최소화 + 캡슐화 + 문서화
          공유변수 최소화가 가장 스레드 안전한 객체를 설계하는 방법이고 불가피하게 공유 변수를 써야 한다면
          내가 관리해야 될 포인트를 한 곳에 모아서 한 객체에서 캡슐화를 해서 그 객체만 관리할 수 있게끔 하는게 차선.
          공유 변수를 사용하게 되면 동기화 정책을 많이 적용하게 되는데 그런 동기화 정책이 코드에 들어가면 코드 파악이 어려워지므로 문서화 필요