- 프로세스와 스레드는 각각 무엇이고 어떤 차이점이 있을까요?
    프로세스는 실행 중인 하나의 애플리케이션입니다.
    운영체제로부터 실행에 필요한 메모리를 할당받아 애플리케이션의 코드를 실행합니다.
    필요한 메모리 영역은 프로그램의 코드를 저장하는 Text 영역, 전역 정적 변수들을 저장하는 Data, 지역 변수들을 저장할 Stack, 동적 메모리 할당을 받을 Heap 영역입니다.

    운영체제에서 각 프로그램들은 동시에 실행할 수 있도록 멀티 프로세스로 동작합니다.
    이는 CPU 자원을 잘게 쪼갠 시간 내에 점유한다는 뜻입니다.
    하나의 프로세스가 CPU 자원을 점유하려는 순간 프로세스의 상태를 불러와야 합니다.
    이 순간에 프로세스 상태를 교체하고 새로운 CPU 레지스터 변수들을 불러오는 작업을 컨텍스트 스위칭(Context Switching)이라고 합니다.
    점유에 벗어나는 순간에 프로세스의 상태를 저장해야 합니다.

    프로세스마다 각자 고유 상태를 갖고 있습니다. 이를 PCB(Process Control Block)이라고 합니다.
    현재 프로세스 상태가 실행 중인지, 대기 중인지를 알려주는 Process State,
    고유 프로세스의 식별값을 나타내는 Process ID,
    다음 실행할 프로그램 코드 위치를 저장하는 Program Counter,
    메모리 정보를 관리할 페이지 테이블과 세그먼트 테이블, CPU의 스케쥴링 큐 포인터와 우선순위 정보, I/O 정보들 등등으로 이루어져 있습니다.

    반면, 스레드는 하나의 프로세스 안에서 실행되는 여러 코드 흐름을 뜻합니다.
    프로세스가 갖고 있는 Text 영역, Data 영역, Heap 영역을 공유하지만, 스레드 내부에서 Stack을 별도로 할당받습니다. 어떤 프로그램이든 하나의 주요 흐름을 실행하는 Main 스레드는 가지고 있습니다.
    Data 영역과 Heap 영역을 공유하기에 다른 스레드와 데이터를 통신할 수 있지만, 어느 스레드가 먼저 실행할 지 모르기에 동기화와 교착 상태에 각별한 주의가 필요합니다.




- 메모리 계층 (상-하층 순) ??
    - 레지스터
    - 캐시
    - 메모리
    - 하드디스크

- 외부 단편화와 내부 단편화란 ??
    - 외부 단편화 : 작업보다 많은 공간이 있더라도 실제로 그 작업을 받아들일 수 없는 경우 (메모리 배치에 따라 발생하는 문제)
    - 내부 단편화 : 작업에 필요한 공간보다 많은 공간을 할당받음으로써 발생하는 내부의 사용 불가능한 공간


- 사용자 수준 스레드 vs 커널 수준 스레드 차이는 ??
  #사용자 수준 스레드
  장점 : context switching이 없어서 커널 스레드보다 오버헤드가 적음 (스레드 전환 시 커널 스케줄러 호출할 필요가 없기 때문)
  단점 : 프로세스 내의 한 스레드가 커널로 진입하는 순간, 나머지 스레드들도 전부 정지됨 (커널이 스레드의 존재를 알지 못하기 때문에)

  #커널 수준 스레드
  장점 : 사용자 수준 스레드보다 효율적임. 커널 스레드를 쓰면 멀티프로세서를 활용할 수 있기 때문이다. 사용자 스레드는 CPU가 아무리 많아도 커널 모드의 스케줄이 되지 않으므로, 각 CPU에 효율적으로 스레드 배당할 수가 없음
  단점 : context switching이 발생함. 이 과정에서 프로세서 모드가 사용자 모드와 커널 모드 사이를 움직이기 때문에 많이 돌아다닐 수록 성능이 떨어지게 된다.



- 페이징(Paging)은 무엇인가요?
    - 물리 메모리를 동일한 크기로 조각조각 냅니다. 이때 하나의 조각을 페이지라고 합니다. 메모리에 올릴 프로세스도 페이지의 크기만큼 조각내서
      물리 메모리에 저장하는 방식입니다. 그렇게 되면 물리 메모리에 연속되서 저장될 필요없이 페이지 단위로 분산되어 저장 가능합니다.
      프로세스 입장에서는 자신의 페이지들이 어디있는지 알아야하는데 이를 위해 페이지 테이블이라는 것이 존재합니다.
    - 프로세스당 하나의 페이지 테이블을 가집니다. 하나의 프로세스 내에서 페이지단위로 물리적 메모리에 저장되기 때문에 주소를 바인딩하기 위해 별도의 테이블이 필요합니다.
      물리메모리 주소를 프레임번호라고도 합니다.


- 페이징 기법에서 문제점이 있나요?
    - 메모리 내부 단편화 문제가 발생합니다. 프로세스를 페이지 단위로 쪼개다보면 페이지 안에 안쓰는 공간이 남습니다.
      예를 들어 100 크기의 프로세스를 30크기의 페이지로 쪼개면 4개의 페이지로 나오고 마지막 페이지는 20이 남습니다.
      이러한 페이지를 물리메모리에 할당하게 되면 20이라는 공간은 아무것도 안하고 남아있는 공간이 됩니다.
    - 외부 단편화 문제는 발생하지 않습니다. 외부단편화는 남아있는 공간은 작은데 그 공간보다 큰 프로세스를 집어넣으려고 할때 발생하는데
      프로세스를 페이지 단위로 나누기 때문에 페이지 단위로 무조건 할당됨을 보장하므로 메모리를 할당하지 못해서 나오는 외부단편화 문제는 발생하지 않습니다.


- 세그먼테이션(Segmentation)이 무엇인가요?
    - 페이지는 프로세스를 크기 단위로 똑같이 나뉘었다면 세그먼테이션은 의미 단위로 메모리를 나누는 것을 의미합니다.
      프로세스를 코드, 데이터, 힙, 스택으로 기능 단위로 정의한다면 4가지로 조각내어 메모리에 저장합니다.
      세그먼테이션은 페이징과 마찬가지로 물리적 주소로 변환하기 위한 세그먼테이션 테이블을 가지고 있습니다.
    - 만약 논리적 주소가 2 / 200 이라면 어떨까요? 2는 세그먼트 번호를 의미하고 200은 떨어진 거리를 의미합니다.
      따라서 세그먼트 2번의 주소가 3500 부터 시작하고 3500에서 200 떨어진 거리인 3700이 2/200 의 논리적주소가 변경된 물리적 주소입니다.
    - 이처럼 세그먼트는 모든 크기가 다르기 때문에 항상 시작점과 limit를 같이 표기해야합니다.


- 세그먼테이션의 단점이 있나요 ??
    - 세그먼테이션은 메모리의 내부단편화 문제가 없습니다. 왜냐하면 필요한 만큼 메모리를 정확하게 할당 받기 때문입니다.
    - 외부 단편화문제가 존재합니다. 세그먼트가 너무 커서 특정 공간에 할당 못할 수도 있습니다. 세그먼트를 쪼개면 가능하겠지만 이는 불가능합니다.


- 가상메모리가 무엇인가요 ??
    - 운영체제는 메모리를 더욱더 효율적으로 사용하기 위해서 도입한 개념입니다.
    - 정의 : 프로세스 전체가 메모리에 올라오지 않아도 실행이 가능하도록 하는 것입니다.

    - 이때까지 메모리에 프로세스 전체가 올라가는 그림이 그려졌습니다. 하지만 가상메모리는 프로세스 전체가 메모리로 올라오지 않습니다.
      어떻게 메모리에 전체 프로세스를 올리지 않더라도 프로세스를 실행할 수 있는 것일까요?
    - 운영체제는 가상메모리 기법을 통해서 프로그램의 논리적 주소 영역에서 필요한 부분만 물리 메모리에 적재하고 직접적으로 필요하지 않은 부분은 디스크(SWAP)에 저장하는 것을 말합니다.

    - 페이징 기법을 쓰는 운영체제에서 가상메모리를 사용한다고 가정해봅시다. 당장 사용될 주소 공간을 page 단위로 메모리에 적재하는 방법을 요구 페이징이라고 합니다.
      요구 페이징에서는 특정 페이지에 대해 cpu 요청이 들어온 후에 해당 페이지를 메모리에 적재합니다. 당장 실행에 필요한 페이지만을 메모리에 적재하기 때문에
      메모리 사용량이 감소하고 프로세스 전체를 메모리에 적재하는 입출력 오버헤드도 감소합니다. 요구페이징 기법에서는 유효/무효 비트를 두어서 각 페이지가 메모리에 존재하는지 표시하게 됩니다.


- 요구 페이징에서 CPU가 요청한 메모리에 없고 디스크에 있다면 어떻게 되나요?
    1) CPU가 페이지 참조
    2) 페이지 테이블을 보니 페이지 상태가 "무효" 상태
    3) MMU에서 페이지 폴트 트랩을 발생
    4) 디스크에서 메모리로 페이지를 가져온 후 "유효" 상태로 변경

    이와 같이 요청한 페이지가 없는 경우를 페이지 폴트(Page fault)라고 합니다.

- 페이지 폴트 발생 후 메모리로 페이지를 가져오려는데 메모리도 부족한 경우라면 어떤 페이지를 교체하나요?
    - 이를 위한 알고리즘이 존재합니다. 바로 페이지 교체 알고리즘입니다.
    - LRU : 가장 오랫동안 사용하지 않은 페이지를 메모리에서 디스크로 방출합니다.
    - LFU : 참조 횟수가 가장 적었던 페이지를 메모리에서 디스크로 방출합니다.


- 프로그램을 메모리에 올릴 때, 적당한 메모리 공간의 위치를 어떻게 효율적으로 정할 수 있을까요?
    메모리에 필요한 공간을 할당할 때, 메모리의 빈 공간을 탐색해서 할당합니다.
    모든 프로그램마다 할당받을 메모리의 크기도 모두 다르기에, 무턱대고 할당하고 해제하기를 반복한다면
    메모리의 빈 공간을 탐색하는데 시간이 많이 들 뿐 더러, 불필요하게 빈 메모리가 많이 생길 것 입니다.

    효율적인 메모리 관리 기법으로 할당할 메모리 주소의 탐색 시간을 줄이고 빈 메모리 공간을 줄입니다.
    이를 관리하는 하나의 하드웨어 단위가 있습니다. 바로 MMU (Memory Management Unit) 입니다.

    최초의 메모리 할당 방법은 연속적으로 할당하는 방법입니다. MMU에서 Offset 레지스터로 CPU가 읽은 가상 주소로부터 물리 주소에 매핑을 시켜주는 역할을 합니다.
    현재 프로그램 영역을 벗어나지 않도록 Limit 레지스터로 주소 접근을 제한하기도 합니다. 만약에 제한을 넘어갔을 때 인터럽트로 시스템에게 예외를 처리하도록 부탁합니다.
    연속적 할당 방법의 장점은 구현이 간단합니다. 그러나 초반에 말했던 단점들은 고스란히 남아있습니다.
    할당과 해제의 과정을 거치면서 메모리 중간에 빈 공간들이 생겨나는데요.

    빈 공간들을 모조리 합치면 새로 들어올 프로그램의 메모리를 옮길 수 있지만,
    연속적으로 할당한다는 특징으로 할당이 불가능합니다.
    총 여유 메모리로 충분히 할당하고도 남지만, 실제로 할당할 수 없는 경우를 외부 단편화(External Fragmentation) 라고 합니다.
    메모리 공간의 빈 공간들을 모두 없애 앞쪽으로 땡기는 Compact 기법이 있습니다. 하나 하나 메모리 영역을 복사하여 빈 공간이 없도록 반복하게 되는데, I/O 문제가 발생할 수 밖에 없습니다.

    이를 해결할 방법은 메모리 영역을 쪼개는 방식입니다. 이를 페이징(Paging) 방식이라고 합니다.
    할당 받은 프로그램의 물리 메모리를 특정 크기의 프레임으로 쪼개 순서에 상관없이 저장합니다.
    그렇다면, 각 프로세스는 어떻게 순서대로 프로그램을 실행할 수 있을까요?
    프로세스 별로 페이지 테이블을 가지고 있습니다. 논리적인 페이징 테이블로 해당하는 실제 메모리 주소에 있는 프레임을 매핑하여 위치를 찾아냅니다.

    페이징 방식의 장점으로 프로그램 메모리를 잘개 쪼개 효율적으로 메모리에 저장하여 외부 단편화를 해소한다는 점이고요. 페이징 방식의 단점으로는 특정 크기의 프레임으로 메모리 영역을 분리하는데요.
    만약에 메모리 크기가 딱 맞지 않다면은 여전히 빈 공간이 생깁니다.
    이를 내부 단편화(Internal Fragmentation)라고 합니다.
    프레임 크기를 줄일수록 페이지 테이블이 커지고 그에 따른 오버헤드는 훨씬 빈번히 발생할 것 입니다.

    물리 메모리에 접근할 때 늘 페이지 테이블에 접근해서 매핑된 물리 메모리에, 총 두 번 접근합니다.
    이를 개선하기 위해 연관 메모리인 TLB(Translation Look-aside Buffer, 변환 색인 버퍼)를 사용합니다.
    페이지 테이블을 대상으로 일종의 캐시 역할을 해줍니다.

    더 나아가 메모리 크기가 커지면서 페이지 테이블을 여러 단계로 계층화 시킨다든지, 해쉬 테이블을 이용한다든지, 하나의 페이지 테이블로 통합시킨다든지 하는 방법들이 나왔습니다.
    자세히는 모르지만 현대에 와서는 멀티 코어 시대인만큼 병렬화를 적극 이용하지 않았을까 싶습니다.


- 콘보이 현상(convoy effect)이란 무엇이고, 콘보이 현상이 발생될 수 있는 CPU 스케줄러 알고리즘은 무엇인지 설명해주세요.
    - 콘보이 현상이란 작업 시간이 긴 프로세스가 먼저 큐에 도착해서 다른 프로세스의 실행 시간이 전부 늦춰져 효율성을 떨어뜨리는 현상을 말합니다.
    - FCFS(First-Come First Served) 스케줄링은 비선점형으로, 순차적으로 먼저 큐에 들어온 작업부터 실행하므로 콘보이 현상이 발생할 수 있습니다.


- 선점형 스케줄링과 비선점형 스케줄링의 차이를 설명해주세요.
    - 선점형은 하나의 프로세스가 다른 프로세스 대신에 CPU를 차지할 수 있음을 말하고,
    - 비선점형은 하나의 프로세스가 끝나지 않으면 다른 프로세스는 CPU를 사용할 수 없음을 말합니다.


- 페이지 교체 알고리즘에 대해 설명해주세요.
    - 페이징 기법으로 메모리를 관리하는 운영체제에서 필요한 페이지가 주기억장치에 적재되지 않았을 시(페이징 부재시) 어떤 페이지 프레임을 선택해 교체할 것인지 결정하는 방법을 페이지 교체 알고리즘이라고 합니다.

    - FIFO(first in first out)
        가장 간단한 알고리즘으로, 메모리에 올라온 지 가장 오래된 페이지를 교체합니다. 간단하고, 초기화 코드에 대해 적절한 방법이며, 페이지가 올라온 순서를 큐에 저장합니다.
    - 최적(Optimal) 페이지 교체
        앞으로 가장 오랫동안 사용되지 않을 페이지를 교체하는 알고리즘입니다. 최적 페이지 교체는 선행 조건이 있는데, 프로세스가 앞으로 사용할 페이지를 미리 알아야 한다는 것입니다.
        이 조건은 실제 활용에선 알 방법이 없기 때문에 최적 알고리즘은 구현이 불가능한 알고리즘입니다. 때문에 연구를 목적으로 주로 사용됩니다.
    - LRU(least-recently-used)
        가장 오래 사용되지 않은 페이지를 교체하는 알고리즘입니다. OPT 알고리즘의 방식과 비슷한 효과를 낼 수 있는 방법이며, OPT 알고리즘보다 페이지 교체 횟수가 높지만 FIFO 알고리즘 보다 효율적입니다.
    - LFU(least-frequently-used)
        참조 횟수가 가장 작은 페이지를 교체하는 알고리즘입니다. 만약 대상인 페이지가 여러 개 일 경우, LRU 알고리즘을 따라 가장 오래 사용되지 않은 페이지로 교체합니다.
    - MFU(most-frequently-used)
        LFU 알고리즘과 반대로, 참조 횟수가 가장 많은 페이지를 교체하는 알고리즘입니다.
    - LFU와 MFU는 실제 사용에 잘 쓰이지 않는다.
        구현에 상당한 비용이 들고,
        최적 페이지 교체 정책을 (LRU 만큼) 제대로 유사하게 구현해내지 못하기 때문이다.


- 페이징과 세그멘테이션
    https://steady-coding.tistory.com/524


- LRU알고리즘이란 Least-Recently-Used
    - 페이지 교체 알고리즘 중에 하나
    - 메모리에 빈 프레임이 없을 때 적재될 페이지를 위해 적재된 페이지 중 누군가는 자신이 차지한 프레임을 비워주어야 하는 교체 대상이 되어야 한다.
    - 어떤 페이지를 선택하는 것이 최적의 기법이 인지 판단하는 다양한 기법들이 있고 페이지 교체 알고리즘이라고 한다.
    - LRU알고리즘은 최근에 사용하지 않는 페이지를 가장 먼저 내려 보내는 알고리즘이다.


- 스케줄러(Scheduler)란?
    - 스케줄러
        - 프로세스를 스케줄링하기 위한 Queue에는 세 가지 종류가 존재한다.
            - Job Queue : 현재 시스템 내에 있는 모든 프로세스의 집합
            - Ready Queue : 현재 메모리 내에 있으면서 CPU를 잡아 실행되기를 기다리는 프로세스의 집합
            - Device Queue : Device I/O 작업을 대기하고 있는 프로세스의 집합

    - 장기 스케줄러(Long-term scheduler or job scheduler)
        - 메모리는 한정되어 있는데 여러 프로세스들이 한 번에 메모리에 올라올 경우에 대용량 메모리(일반적으로 디스크)에 임시로 저장된다.
        - 이 Pool에 저장되어 있는 프로세스 중 어떤 프로세스에 메모리를 할당하여 Ready Queue 로 보낼지 결정하는 역할을 한다.
            - 메모리와 디스크 사이의 스케줄링을 담당
            - 프로세스에 메모리(및 각종 리소스)를 할당(admit)
            - degree of multiprogramming 제어
              (메모리에 여러 프로그램이 올라가는 것) 몇 개의 프로그램이 올라갈 것인지를 제어
            - 프로세스의 상태
              new => ready(in memory)

    - 중기 스케줄러(Medium-term scheduler or Swapper)
        - 여유 공간 마련을 위해 아직 실행하지 않아도 되는 프로세스를 통째로 메모리에서 제거하고 디스크로 쫓아냄 (Swapping)
        - Performance (속도)는 느려지지만 여러 프로세스르 실행시키기 위해서는 반드시 필요한 작업

    - 단기 스케줄러(short-term scheduler or CPU scheduler)
        - CPU 와 메모리사이의 스케줄링을 담당
        - 굉장히 자주 돌며 Ready Queue 에 존재하는 프로세스 중 어떤 프로세스를 running 시킬 것인지 결정
        - 시간을 엄청 많이 나누어 그 순간마다 여러 프로세스를 실행시키는 즉, 멀티태스킹을 하게 해주는 스케줄러


- 메모리 관리 전략
    - 제한된 물리 메모리의 효율적인 사용과 메모리 참조 방식을 제공하기 위해 필요

    - 연속 메모리 할당
        - 프로세스를 메모리에 연속적으로 할당하는 기법
        - 할당과 제거를 반복하다보면 Scattered Holes가 생겨나고 이로 인한 외부 단편화가 발생

        - Scattered Holes
            - 연속 메모리 할당에서 외부 단편화를 줄이기 위한 방식 3가지
                최초 적합(First-fit)
                    메모리를 순차적으로 탐색하여 제일 먼저 발견한 적절하게 들어갈 수 있는 곳을 찾아 프로세스를 적재하는 방법이다.

                최적 적합(Best-fit)
                    메모리를 탐색하여 메모리 공간 중에서 제일 적절하게 들어갈 수 있는 곳을 찾아 프로세스를 적재하는 방법이다.
                    메모리 공간의 크기와 프로세스의 크기 차이가 제일 적은 경우

                최악 적합(Worst-fit)
                    메모리에 넣는데 크기와 제일 안 맞는 공간(프로세스보다 큰 메모리 공간 중에서)에 프로세스를 넣는 방식이다.

    - 페이징
        - 패이징이란 논리주소의 고정된 페이지라고 불리는 블록들로 분할 관리하는 기법
        - 각각의 페이지는 물리 메모리의 프레임과 맵핑
        - 페이지를 가리키는 논리주소에서 프레임을 가리키는 물리주소로 변환
        - 결론은 외부 단편화를 보완하기 위해 사용

        1.logical address를 동일한 크기로 자름(고정 분할)
        2.physical address도 이것과 동일한 크기로 자름
        3.A,B프로세스의 고정 분할된 일부의 page는 물리메모리의 어디에 배치되고 어디에 배치되고.... 계속 하게 되면 외부 단편화가 발생하지 않음

    - 세그멘테이션
        - 페이징기법과 반대로 논리 메모리와 물리 메모리를 같은 크기가 아닌 다른 크기의 논리적 단위인 세크멘트로 분할
        - 세그먼트의 크기는 일반적으로 같지 않다.
        - 메모리를 자르는 방법을 빼고 메모리에 힐당하는 방법은 페이징 기법과 방 같다.
        - 세그멘테이션 페이징 혼용 기법
            - 페이징과 세그멘테이션도 각각 내부 단편화와 외부 단편화가 발생
            - 페이징과 세그멘테이션을 혼용해 이러한 단편화를 최대한 줄이는 전략
            - 프로세스를 세그먼트(논리적 기능 단위)로 나눈 다음 세그먼트를 다시 페이지 단위로 나누어 관리
            - 매핑 테이블을 두 번 거쳐야하므로 속도가 느려짐


- 가상 메모리
    - 가상 메모리 기법은 프로그램 전체가 아닌 필요한 일부부만 실제 메모리에 올리는 기법입니다.
    - 실제 사용하는 메모리는 작다는 점에서 고안된 기술
    - 즉, 가상메모리는 프로세스의 물리 메모리와 논리 메모리를 분리하기 위해 생겨난 것입니다.

    - 가상 메모리를 사용하는 이유
        - 각 프로세스마다 충분한 메모리를 할당하여 사용하기에는 메모리 크기에 한계가 있다.
        - 프로세스간 메모리 영역간 침범 방지

    - '가상메모리가 없는 경우'
        RAM의 메모리가 4GB라고 하고, 프로세스 A,B에 필요한 메모리가 4GB이라면
        메모리에 프로세스 A가 먼저 할당이 된다면 , 프로세스 B는 할당받을 메모리가 부족하여 사용할 수 없다.
    - '가상메모리가 있는 경우'
        RAM의 메모리가 4GB라고 하고, 프로세스 A,B,C가 있다고 한다면,
        프로세스가 현재 사용되는 메모리 만큼만 물리 메모리(RAM)에 할당과 해제를 반복하여
        메모리를 사용한다면 여러 프로세스가 사용 할 수 있다.


- 캐시의 지역성 원리
    - 캐시 메모리는 속도가 빠른 장치와 느린 장치간의 속도차에 따른 병목 현상을 줄이기 위한 범용 메모리이다.
      이러한 역할을 수행하기 위해서는 CPU 가 어떤 데이터를 원할 것인가를 어느 정도 예측할 수 있어야 한다.
        - 캐시 메모리에서 원하는 데이터를 찾는다면 메인 메모리까지 가서 찾지 않아도 되기 때문에 성능 향상
        - 캐시 메모리에 원하는 데이터에 적중률 성능의 관건
        - 이때 적중율을 높이기 위해 데이터 지역성 원리를 사용한다고 한다.

    - 시간 지역성
        - 최근에 참조된 주소의 내용은 곧 다음에 다시 참조되는 특성
        ex) for나 while 같은 반복문에 사용하는 조건 변수처럼 한번 참조된 데이터는 잠시 후에 또 참조될 가능성이 높다

    - 공간 지역성
        - 대부분의 실제 프로그램이 참조된 주소와 인접한 주소의 내용이 다시 참조되는 특성
        - 캐시 메모리에 데이터를 저장할 때 공간 지역성을 최대한 활용하기 위해 해당 데이터뿐만 아니라 옆 주소의 데이터도 같이 가져와 미래에 쓰일 것을 대비한다.
        ex) A[0], A[1]과 같은 데이터 배열에 연속으로 접근할 때 참조된 데이터 근처에 있는 데이터가 잠시 후에 사용될 가능성이 높다


- 사용자 수준 스레드와 커널 수준 스레드
    - 사용자 레벨 스레드는 말그대로 우리가 #include 혹은 import를 통해 스레드를 이용하는 것을 의미한다.
    - 커널 레벨 스레드는 커널 내에 있는 스레드를 의미하게 되고 위와같이 3가지 방법으로 나뉜다.

    - Pure user-level
        커널 스레드 1개당 사용자 스레드 n개를 의미한다. 즉, 1 : n 방식이다.
        이 방식같은 경우에는 커널은 사용자 스레드가 100개가 있어도 전혀 모르기 때문에 사용자 스레드에서 I/O가 하나라도 발생하면 해당 프로세스는 I/O가 풀릴 때 까지 영원히 block된다.
    - Pure Kernel-level
        n개의 커널 스레드가 n개의 사용자 스레드를 담당하게 된다. 즉 1:1 방식이다. 1:1 방식이기에 병렬성은 좋으나 효율성 면에서 다소 떨어진다.
    - Combined
        커널 스레드와 사용자 스레드를 혼합하여 사용하는 방식이다. 위의 두 방식의 장점을 혼합한 방식이라 생각 할 수 있다.

    - 커널 레벨 스레드
        - 정의
            - 커널 스레드는 가장 가벼운 커널 스케쥴링 단위다.
            - 하나의 프로세스는 적어도 하나의 커널 스레드를 가지게 된다.
            - 커널 영역에서 스레드 연산을 수행하게 된다.
            - 커널이 스레드를 관리하기 때문에 커널에 종속적이다.
            - 프로그래머 요청에 따라 스레드를 생성하고 스케줄링하는 주체가 커널이면 커널 레벨(Kernel Level) 스레드라고 한다.

        - 장점
            - 프로세스의 스레드들을 몇몇 프로세서에 한꺼번에 디스패치 할 수 있기 때문에 멀티프로세서 환경에서 매우 빠르게 동작한다.
            - 다른 스레드가 입출력 작업이 다 끝날 때까지 다른 스레드를 사용해 다른 작업을 진행할 수 있다.
            - 커널이 각 스레드를 개별적으로 관리할 수 있다.
            - 커널이 직접 스레드를 제공해 주기 때문에 안정성과 다양한 기능이 제공된다.

        - 단점
            - 스케줄링과 동기화를 위해 커널을 호출하는데 무겁고 오래걸린다.(저장한 내용을 다시 불러오는 과정이 필요)
            - 즉, 사용자 모드에서 커널 모드로의 전환이 빈번하게 이뤄져 성능 저하가 발생한다.
            - 사용자가 프로그래밍할 때 구현하기 어렵고 자원을 더 많이 소비하는 경향이 있다.

    - 사용자 레벨 스레드
        - 정의
            - 사용자 영역에서 스레드 연산을 수행한다.
            - 사용자 영역에서 스레드 연산을 수행하기 때문에 운영체제에 투명하다.
            - 커널에 의존적이지 않은 형태로 스레드의 기능을 제공하는 라이브러리를 활용하는 방식이 사용자 레벨(User Level) 스레드다.

        - 장점
            - 운영체제에서 스레드를 지원할 필요가 없다.
            - 스케줄링 결정이나 동기화를 위해 커널을 호출하지 않기 때문에 인터럽트가 발생할 때 커널 레벨 스레드보다 오버헤드가 적다.
            - 즉, 위의 말은 사용자 영역 스레드에서 행동을 하기에 OS Scheduler의 context switch가 없다(유저레벨 스레드 스케줄러를 이용).
            - 커널은 사용자 레벨 스레드의 존재조차 모르기 때문에 모드 간의 전환이 없고 성능 이득이 발생한다.

        - 단점
            - 시스템 전반에 걸친 스케줄링 우선순위를 지원하지 않는다. (무슨 스레드가 먼저 동작할 지 모른다.)
            - 프로세스에 속한 스레드 중 I/O 작업등에 의해 하나라도 블록이 걸린다면 전체 스레드가 블록된다.

    * 커널?
        운영체제의 다른 모든 부분에 여러 기본적인 서비스를 제공하고 컴퓨터 하드웨어와 프로세스의 보안을 책임진다. 한정된 시스템 자원을 효율적으로 관리하여 프로그램의 실행을 원활하게 한다.

    * Context Switching
        현재 진행하고 있는 Task(Process, Thread)의 상태를 저장하고 다음 진행할 Task의 상태 값을 읽어 적용하는 과정


- 스와핑(Swapping)
    프로그래밍 언어에서 스왑(Swap)이라는 단어는 두 개의 값을 바꾼다는 뜻을 가지고 있다. OS 에서의 의미도 이와 크게 다르지 않다.
    예를 들어 유저 공간(주기억장치)이 있는데 이 곳은 최대 10개의 프로세스(Process)를 올릴 수 있다고 가정하고 현재 메모리를 꽉 차지하고 있다.
    이 상황에서 11번째 프로세스가 실행된다면 당연히 메모리가 가득 차서 올릴 수 없다. 그래서 10개의 프로세스 중에서 하나의 프로세스를 잠깐 내리고
    그 사이에 11번째 프로세스를 실행시키는 방법이다. 어떤 하나의 프로세스가 이벤트가 발생하기까지 기다리고 있는데 1시간이 넘었다.
    그렇다면 이 프로세는 앞으로도 쭉 기다릴 확률이 높다. 그렇다면 이 프로세스를 잠깐 이 공간(주기억장치)에서 쫓아내고 이 공간에 새로운 프로세스를 넣는 것이다.
    당연히 쫓아낼 때 그냥 쫓아내면 안되고 잠깐 다른 곳에 저장을 해놔야한다. 그리고 그 다른 곳은 하드디스크, SSD 와 같은 Secondary storage(보조기억장치)가 된다.
    이렇게 프로세스 단위로 쫓아내는 것을 Swap out 이라고 한다.
    시간이 지나고 아까 그 쫓아낸 프로세스 이벤트 요청이 왔다. 그럼 이 프로세스를 다시 메모리에 올려서 실행시키면 되고 이렇게 다시 메모리로 로딩하는 것을 Swap in 이라고 한다.
    이렇게 프로세스 단위로 Swap in, Swap out 하는 것을 Swapping 이라고 한다.
        - 하드디스크(보조기억장치)에 있던 것을 메모리에 다시 로딩하고 실행한다. 이렇게 교체 시스템에서 나타나는 Context Switching 시간은 생각보다 꽤 높다.
        - 시간은 오래 걸리지만 부족한 메모리에 더 많은 프로세스를 실행할 수 있다는 큰 장점이 있다.
        - 이러한 Swapping 기법은 이후 가상 메모리 관리 방법인 페이징 기법으로 발전했다.


- 메모리 단편화(Memory Fragmentation)
    - 주기억장치에서 메모리의 공간이 작은 조각으로 나누어져, 사용하기에 충분한 양의 메모리가 존재는 하지만 사실상 사용이 불가능한 경우 메모리 단편화가 발생했다고 한다.
      이러한 메모리 단편화는 내부 단편화(Internal Fragmentation)와 외부 단편화(External Fragmentation)로 구분할 수 있다.
        - 내부 단편화(Internal Fragmentation)
            필요한 양보다 더 큰 메모리가 할당이 되어 할당 된 메모리 내부에 사용하는 메모리 공간 이외에 사용하지 않는 메모리 공간이 발생했을 때를 말한다.

        - 외부 단편화(External Fragmentation)
            메모리가 할당이 되고 해제가 되는 작업이 반복될 때 작은 단위의 메모리가 띄엄띄엄 존재하게 된다.
            이 때, 비어있는 메모리의 공간은 충분한 양이지만 실제로 사용할 수 없는 경우를 말한다.

        - 이러한 메모리 단편화를 해결하는 방법에는 여러가지가 있다.
            - 압축(Compaction) 기법
                메모리 공간들을 하여, 단편화로 인해 분산되어 있는 메모리 공간들을 하나로 합치는 기법
            - 통합(Coalescing) 기법
                단편화로 인해 분산된 메모리 공간들을 인접해 있는 것끼리 통합시켜 큰 메모리 공간으로 합치는 기법

            압축기법과 통합기법의 차이는 압축은 재배치가 일어나지만 통합은 인접한 공간끼리 통합된다는 차이가 있다. 하지만 이렇게 비어 있는 공간을
            연속적인 공간으로 만들고 움직이는 작업은 메모리를 Copy 해야하고 이 시점에서 반드시 I/O Problem 이 발생하게 된다.
            하드디스크가 병목되기 때문에 좋은 방법은 아니다. 이는 결국 페이징(Paging)의 배경이 된다.


- 페이징(Paging) 기법과 세그멘테이션(Segmentation) 기법
    - 가상메모리
        우선 가상 메모리를 관리하는 기법인 페이징기법과 세그멘테이션기법을 살펴보기전에 가상메모리에 대해 알아보자.
        가상 메모리는 메모리에 로드된 즉, 실행중인 프로세스가 가상의 공간을 참조하여 마치 커다란 물리메모리를 갖고 있는 것처럼 착각하게 만드는 것이다.
        이러한 가상 메모리는 각 프로세스 당 메인 메모리와 동일한 크기로 하나씩 할당되며 그 공간은 보조기억장치(HDD, SSD) 공간을 이용한다.
        프로세스의 일부만 메모리에 로드하고 나머지는 보조기억장치에 두는 형태이다. 이렇게 할당이 되면 MMU(메모리 관리 장치로 CPU 코어 안에 탑재되어서
        가상 주소를 실제 메모리 주소로 변환해주는 장치) 에 의해 물리 주소로 변환이 된다. MMU 를 더 설명하기에는 내용이 길어지기에 생략하기로 한다.
        다만 프로세스를 동작시키기 위해서는 가상 주소가 아닌 실제 물리 주소가 필요하고 가상 메모리에 있는 가상 주소를 물리 주소로 변환시켜주는 장치라고 이해하고 넘어가자.

    - 페이징(Paging) 기법
        비어있는 메모리(Hole)보다 크기 때문에 발생한다. 그리고 이 Hole 의 크기도 제각각, 프로세스의 크기도 제각각이다.
        그래서 이러한 외부 단편화를 완벽히 발생시키지 않기 위한 방법이 페이징(Paging) 기법이다. 페이징은 Logical Address(프로세스) 를 동일한 크기로 자르고,
        Physical Address(메모리) 도 이것과 동일한 크기로 자른다(Frame 단위). 그리고 개별 페이지는 순서에 상관없이 Physical Memory 에 있는
        프레임에 Mapping 되어 저장된다고 볼 수 있다. 그림을 보면 조금 더 쉽게 이해가 된다.

        프로세스를 굳이 연속적으로 배치할 필요가 없다. 그래서 Paging 을 통해 외부단편화 문제를 해결할 수 있다.

        하지만 페이징(Paging)은 내부 단편화 문제를 해결할 수는 없다.
        프로세스의 크기가 나누어져있는 Page 의 크기에 딱 맞게끔 나누어진다는 보장이 없기 때문이다.
        한 페이지의 크기가 7K 일때 45K 의 프로세스를 실행한다고 하면 3K의 내부 단편화가 발생할 수 밖에 없다. 그럼 페이지의 크기를 더 잘게 쪼개면 되지 않느냐고 할 수 있다.
        하지만 페이지의 크기가 너무 작아질수록(혹은 너무 커질수록) 발생되는 문제점들이 있다.
            - 페이지 단편화 감소(증가)
            - 한 개의 페이지를 주기억장치로 이동하는 시간이 줄어든다.(늘어남)
            - 프로세스 수행에 필요한 내용만 주기억장치에 적재 가능(불가능)
            - 기억장치 효율성이 높아짐(낮아짐)
            - 페이지 맵 테이블의 크기가 커짐(작아짐)
            - Mapping 속도가 늦어진다.(빨라짐)
            - 입/출력 시간의 증가(감소)

    - 세그멘테이션(Segmentation) 기법
        - Paging 기법은 외부 단편화 문제를 해결할 수 있었지만, 내부 단편화 발생의 문제가 있었다. 그래서 내부 단편화 문제를 해결하기 위한 방법이 세그멘테이션(Segmentation) 기법이다.
          프로세스를 일정한 단위인 페이지 단위로 잘랐다면 물리적인 단위인 세그먼트 단위로 자르는 것이 세그멘테이션 기법이다.
        - 세그멘테이션은 프로세스를 세그먼트(서로 다른 크기를 가지는 논리적인 블록이 연속적인 공간에 배치되어 있는것)의 집합으로 생각한다.

        세그먼트라고 부른다. 그리고 이렇게 영역별로 쪼개는 기술을 세그멘테이션이라고 한다.
        사실 하나의 프로세스가 동작하기 위해서는 기본적으로 코드, 데이터, 스택 세 가지의 세그먼트는 항상 가지고 있다. 그리고 더 들어가 본다면
        코드에서도 main 함수가 있고 다른 함수들 또한 존재할 수 있다. 데이터를 본다고 해도 어떠한 구조체가 존재할 수도, 배열이 있을 수도 있다.
        그래서 세그멘테이션은 물리적인 크기의 단위가 아닌 논리적 내용의 단위로 자르기 때문에 세그먼트들의 크기는 일반적으로는 같지 않다.
        세그멘테이션을 사용하면 세그먼트 테이블(Segment Table)이라고 세그먼트의 시작주소(base)와 세그먼트의 길이(limit) 정보가 담긴 테이블을 운용한다.
        이로 인해 각각의 세그먼트를 offset 단위로 관리할 수 있다.

        MMU(CPU 코어 안에 탑재되어서 가상 주소를 실제 메모리 주소로 변환해주는 장치) 내의 재배치 레지스터를 이용하여 논리 주소를 물리 주소로 바꾸어 주는 방식을 취한다.
        MMU 는 세그먼트 테이블로 CPU 에서 할당한 논리 주소에 해당하는 물리 주소의 위치를 가지고 있다. 세그먼트는 세그먼트 테이블에 연속적으로 저장되기 때문에
        CPU 는 프로세스가 연속된 메모리 공간에 위치한다고 착각을 하게 된다. 하지만 세그멘테이션 기법은 동적 할당(세그먼트들의 크기가 다르기 때문에
        미리 분할해 둘 수 없고 그때 그때 빈 공간을 찾아 적재)이기 때문에 외부 단편화가 발생할 수 있다.

    - 페이징(Paging) + 세그멘테이션(Segmentation)
        페이징은 내부 단편화 문제를 가지고 있고 세그멘테이션은 외부 단편화 문제를 가지고 있다. 그래서 두 방식을 모두 사용하여 장점만을 가져오고자 한다.
        따라서 세그멘트를 페이징하는 방식을 취한다. A 우선 프로세스를 처음에 세그먼트 단위로 자른다. 의미 있는 단위로 나누게 되면 정보 보호와 공유를 하는 측면에서
        세그먼트의 이점을 가져오면서 내부단편화를 막는다. 하지만 외부단편화가 발생할 수 있기 때문에 잘라진 세그먼트를 다시 일정 간격인 페이지 단위로 자르는 페이징 기법을 취한다.
        그래서 메모리에 적재하게 되면 페이징의 일정 단위로 다시 잘렸기 때문에 외부 단편화가 발생하지 않는다. 하지만 이와 같은 경우에는 세그먼트 테이블과
        페이징 테이블 두 가지를 모두 겨쳐야하므로 속도 면에서는 조금 떨어질 수 있다. 실제로 x86 메모리 관리를 이런 식으로 두 가지 기법을 섞어 작업을 처리한다.